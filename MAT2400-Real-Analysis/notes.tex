\input{preamble.tex}

\title{\huge{Real Analysis}}
\author{\LARGE{Thobias Høivik}}
\date{\Large{Spring 2026}}

\begin{document}
\maketitle

\newpage
\tableofcontents

\newpage
\section{Introduction}
The following is intended for anyone who stumbles over these notes. 
This is intended to be my personal notes in real analysis. 
I will hopefully be attending MAT2400 Real Analysis at 
the University of Oslo in the spring of 2026. However, 
as I am not a program student at this institution, but 
just someone who takes individual courses there 
of my own volition, I do not and cannot attend lectures and 
therefore I have to learn the material on my own. 
As far as I understand, while this course is called Real Analysis, 
it is a bit different than a first course from what I understand. 
The earlier exams give a hint of functional analysis and 
also include topics such as fourier analysis, meassure- and integration
theory among other things. Thus the different supplementary 
coursematerial I will use to aid myself in learning the content 
of this course will most likely be a bit scattered and all over the 
place, which these notes will undoubtedly reflect. I will 
do my best to keep things organized for my own sake, but keep 
this in mind if you are someone who intends to use these 
notes to learn Real Analysis. 

\newpage 
\section{Basic Banch Space theory}
The following section of notes is derived from the first video 
in the lecture series MIT 18.102 Introduction to Functional 
Analysis, Spring 2021 (found on youtube). 

\begin{defn}[Vector Space]
    \label{defn:vector_space}
    A vector space $V$ over a field $\mathbb F$ is a nonempty 
    set of elements called "vectors" together with 
    a binary operation $+$ on $V$ and a binary function 
    $\cdot$ which maps elements of $V, \mathbb F$ to $V$ 
    satisfying: 

    \begin{enumerate}
        \item Associativity of vector addition: 
            $$ 
                u + (v+w) = (u+v)+w, \forall u,v,w \in V
            $$
        \item Commutativity of vector addition: 
            $$ 
                u + v = v + w, \forall u,v \in V
            $$ 
        \item Identity element: 
            $$ 
                \exists 0 \in V : v + 0 = 0 + v = v, \forall v \in V
            $$ 
        \item Each $v \in V$ has an inverse $-v$ under the 
            vector-addition operation.
        \item Scalar multiplication is compatible with field 
            multiplication: 
            $$ 
                a(bv) = (ab)v
            $$ 
            where $a,b \in \mathbb F$ and $v \in V$. 
        \item The multiplicative identity $1 \in \mathbb F$ 
            satisfies: 
            $$ 
                1v = v, \forall v \in V
            $$ 
        \item Distributivity of scalar multiplication with respect 
            to vector addition: 
            $$ 
                a(u+v) = au + av
            $$ 
            where $a \in \mathbb F$ and $u,v \in V$. 
        \item Distributivity of scalar multiplication with 
            respect to field addition: 
            $$ 
                (a+b)v = av + bv
            $$ 
            where $a,b \in \mathbb F$ and $v \in V$. 
    \end{enumerate}

    When proving that something is a vector space, most 
    of these follow naturally from showing closure under 
    addition and scalar multiplication and those two properties, 
    are generally enough to show that it is indeed a vector space. 

    A subspace $U$ of $V$ is a set $U \subseteq V$ which is also 
    a vector space. It is enough to show that $U \subseteq V$ and 
    that it is closed under the two operations. 
\end{defn}

\newpage 
Some typical examples of vector spaces are 
$\mathbb F^n$ where $\mathbb F$ is the reals or the complex 
numbers. We also have spaces like the space of real polynomials 
of degree $\leq n$, i.e. $\mathcal P_n = 
\{\sum_{i=0}^n \alpha_i x^i : \alpha_i \in \mathbb R\}$, 
which is itself a subspace of the space of continuous real-valued 
functions $C(\mathbb R)$. 

So $\mathbb R^2$ and $C(\mathbb R)$ 
are both vector spaces over $\mathbb R$, but 
they have one really big difference, that being the dimension. 

\begin{defn}
    \label{defn:linear_independence}
    Let $V$ be a vector space. A set $\{v_1,\ldots, v_n\} \subseteq V$
    is linearly independent if  
    $$ 
        \displaystyle\sum_{i=1}^n \alpha_i v_i = 0 
        \Leftrightarrow \alpha_1 = \dots = \alpha_n = 0 \in \mathbb F
    $$ 

    Note: the right-to-left direction of this implication is 
    always true. 
\end{defn}

The two spaces discussed above are different in dimension, 
$\mathbb R^2$ being $2$-dimensional and the other being 
infinite-dimensional. 
One definition of finite-dimensional is that every linearly 
independent set in the space is finite. 
I however like the definition using bases more. 
Both of these definitions are equivalent. 

We won't give a rigorous definition of a basis, but in short 
a basis of $V$ is a linearly independent set of vectors which spans 
$V$, i.e. every vector in $V$ can be expressed as a linear combination
of basis-vectors. If the basis is finite then $V$ 
is finite dimensional. Moreover, if the basis is finite then the 
dimension of $V$ is the number of basis-vectors. Note that 
if a finite dimensional space $V$ has a basis with $n$ elements 
then every basis of $V$ has $n$ elements. A space is  
infinite-dimensional if no finite set of linearly independent vectors 
spans the space. 

\newpage 
\subsection{Norms and Metrics}

\begin{defn}[Norm]
    \label{defn:norm}
    Let $V$ be a vector space. 
    A norm $|| \cdot || $ is a function 
    from $V \to [0,\infty)$ satisfying: 
    \begin{enumerate}
        \item $|| v || = 0$ if and only if 
            $v = 0$. 
        \item $|| \alpha v || = |\alpha| \cdot ||v||$ where 
            $\alpha$ is an element of the ground field. 
        \item $||v + w|| \leq ||v|| + ||w||$.
    \end{enumerate}
    
    The tuple $(V, ||\cdot||)$ is called a normed space. 
\end{defn}

\begin{ex}
    \label{ex:lp_norms}
    $||x||_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}$ defines 
    a norm on $\mathbb R^n$.

    In fact it constitutes a norm on $\mathbb C^2$ as well. 
    Formally, if we take $\mathbb F = \mathbb R$ or  
    $\mathbb F = \mathbb C$ the p-norm of a vector 
    $v \in \mathbb F^n$ ($p \in [1,\infty]$) is
    $$ 
        ||v||_p := 
        \begin{cases}
            \left(\displaystyle\sum_{i=1}^n |v_i|^p\right)^{1/p} & 
            p < \infty\\ 
            \max_{i=1,\dots,n}|v_i| & p = \infty
        \end{cases}
    $$ 
\end{ex}

Norms give us a notion of the "length" of a vector.  
Now all we need to do analysis on spaces is a notion of 
distance. Intuitively, norms already give us a notion of 
distance from $0$. 

\begin{defn}
    \label{defn:metric}
    Let $X$ be a set. 

    A metric is a function 
    $d:X^2 \to [0,\infty)$ satisfying: 
    \begin{enumerate}
        \item $d(x,y) = 0$ if and only if $x = y$. 
        \item $d(x,y) = d(y,x)$. 
        \item $d(x,z) \leq d(x,y) + d(y,z)$. 
    \end{enumerate}
\end{defn}

The metric gives us a notion of distance. 
In a typical first course in analysis where we work on 
the reals, $d(a,b) = |a - b|$ is the metric we deal with. 

\newpage 
\begin{prop}
    Let $V$ be a normed space with norm $||\cdot||$. 
    Then we can define the distance (a metric) between two vectors 
    by 
    $$ 
        d(x,y) := \left|\left| x - y \right|\right|
    $$ 

    In other words you can define a metric in terms of the norm 
    in any normed space. This metric is usually refered to 
    as the metric induced by the norm. 
\end{prop}

We won't provide a proof of this as it's fairly intuitive. 
Now we can get a sense of convergence and continuity in 
vector spaces by saying that a sequence $\{a_n\}_{n \in \mathbb N}$
converges to a value $a$ if 
$$ 
    \forall \varepsilon > 0, \exists N \in \mathbb N : 
    n \geq N \Rightarrow ||a_n - a || < \varepsilon 
$$ 
and a linear transformation (look up definition if necessary) 
$T \in \mathcal L(U,V)$ is (uniformly) continuous if 
$$ 
    \forall \varepsilon > 0, \exists \delta > 0 : 
    ||x - y||_U < \delta \Rightarrow 
    ||Tx - Ty||_V < \varepsilon
$$ 
for every $x,y \in U$. Notice that if you replace $||x-y||$ with 
$d(x,y)$ it looks like the standard definitions in terms 
of metric spaces. 

\newpage 
\subsection{Banach Spaces}
\begin{defn}[Banach Space]
    \label{defn:banach_space}
    A normed space $V$ is a Banach Space if it is 
    complete with respect to the metric induced by the norm, meaning
    that every cauchy sequence converges to a value in the 
    space. 
\end{defn}

\begin{ex} 
    $\mathbb R^n$ or $\mathbb C^n$ form Banach Spaces 
    with respect to the $\ell^p$ norms (see \Cref{ex:lp_norms}).
\end{ex}

\begin{thm}
    If $X$ is a complete metric space, then 
    $C_\infty(X)$ is a Banach Space. 
\end{thm}

Recall that $C_\infty(X)$ is the space of bounded continuous 
functions on $X$.

\begin{proof}
    We show that every Cauchy sequence in $C_\infty(X)$ converges 
    to an element
    of $C_\infty(X)$.

    Let $\{u_n\}_{n=1}^\infty \subseteq C_\infty(X)$ be a Cauchy 
    sequence with
    respect to the supremum norm. Then for every $\varepsilon > 0$ 
    there exists
    $N \in \mathbb{N}$ such that
    \[
        \|u_n - u_m\|_\infty < \varepsilon \quad \text{for all } 
        n,m \ge N.
    \]
    Equivalently,
    \[
        |u_n(x) - u_m(x)| < \varepsilon
        \quad \text{for all } x \in X \text{ and all } n,m \ge N.
    \]

    Fix $x \in X$. Then $\{u_n(x)\}_{n=1}^\infty$ is a 
    Cauchy sequence in
    $\mathbb{R}$ (or $\mathbb{C}$), since
    \[
        |u_n(x) - u_m(x)| \le \|u_n - u_m\|_\infty.
    \]
    Because $\mathbb{R}$ (or $\mathbb{C}$) is complete, the limit
    \[
        u(x) := \lim_{n\to\infty} u_n(x)
    \]
    exists. This defines a function $u : X \to \mathbb{R}$.

    We now show that $u_n \to u$ uniformly on $X$. Let 
    $\varepsilon > 0$ and
    choose $N$ such that $\|u_n - u_m\|_\infty < \varepsilon$ 
    for all $n,m \ge N$.
    Fix $n \ge N$ and $x \in X$. Taking the limit $m \to \infty$ gives
    \[
        |u_n(x) - u(x)|
        = \lim_{m\to\infty} |u_n(x) - u_m(x)|
        \le \varepsilon.
    \]
    Since $x \in X$ was arbitrary, it follows that
    \[
        \|u_n - u\|_\infty \le \varepsilon \quad \text{for all } 
        n \ge N.
    \]
    Thus $u_n \to u$ uniformly on $X$.

    Since each $u_n$ is bounded and the convergence is uniform, 
    the limit
    function $u$ is bounded. Moreover, since each $u_n$ 
    is continuous and
    uniform limits of continuous functions are continuous, 
    $u$ is continuous
    on $X$.

    Therefore $u \in C_\infty(X)$ and $\{u_n\}$ converges to $u$ in the
    supremum norm. Hence $C_\infty(X)$ is complete, 
    and thus a Banach space.
\end{proof}

\newpage 
\section{A step back into Calculus Theory}
The following section is largely in accordance with 
chapter 2 of Lindstrøm's Spaces: An Introduction 
To Real Analysis. 

\begin{defn}[Limit of a sequence]
    \label{defn:limit_sequence}
    Let $(x_n)$ be a sequence of real numbers and $x \in \mathbb R$. 

    We say 
    $$ 
        x_n \to x
    $$ 
    if for every $\varepsilon > 0$, there exists a natural number 
    $N$ such that 
    $$ 
        |x_n - x| < \varepsilon, \; \forall n \geq N
    $$ 
\end{defn}
This is among the most important definitions in a first 
course in Real-Analysis.   
Intuitively what it captures is the sense of being able 
to get arbitrarily close to a value. 
We will all be familiar with examples from 
calculus like $\lim_{n\to\infty} \frac{1}{n} = 0$. 

\begin{thm}
    \label{thm:limit_unique}
    If a sequence converges, then its limit is unique. 
\end{thm}
\begin{proof}
    Suppose, for a contradiction, that we have some sequence 
    $(x_n)$ with 
    $$ 
        x_n \to x \text{ and } x_n \to y
    $$ 
    of course with $x \neq y$.

    $x_n$ converges so we can choose any $\varepsilon > 0$ 
    for the condition in \cref{defn:limit_sequence} to hold. 

    Consider the case of $\varepsilon = \frac{|x-y|}{2}$. 
    $\varepsilon > 0$ since $x \neq y$ and is therefore a value 
    for which the condition must hold. Namely, 
    $$ 
        |x_n - x| < \varepsilon \text{ and } |x_n - y| < \varepsilon
    $$ 
    leading to
    $$ 
        |x - x_n| + |x_n - y| < 2\varepsilon = |x - y|
    $$ 
    which, via triangle inequality, yields 
    $$ 
        |x-y| = |x - x_n + x_n - y| \leq |x - x_n| + |x_n - y| < |x-y| 
    $$ 
    in particular 
    $$ 
        |x-y| < |x-y|
    $$ 
    which is not possible, a contradiction. 

\end{proof}

\newpage 
\begin{thm}[Algebra of Limits]
    \label{thm:algebra_limits}
    If $x_n \to x$ and $y_n \to y$, then: 
    \begin{enumerate}
        \item $x_n + y_n \to x + y$ 
        \item $x_ny_n \to xy$
        \item If $y_n \neq 0$ and $y \neq 0$, then $\frac{x_n}{y_n}
            \to \frac{x}{y}$.
    \end{enumerate}
\end{thm}
\begin{proof}[Proof of (1): Sum of Limits]
    Let $(x_n)$ and $(y_n)$ be convergent sequences with 
    $x_n \to x$ and $y_n \to y$. 

    Let $\varepsilon > 0$. Since both sequences converge to their 
    respective limits we have some 
    $N_1, N_2 \in \mathbb N$ such that 
    \begin{align*}
        |x_n - x| &< \varepsilon/2, \: \forall n \geq N_1 \\ 
        |y_n - y| &< \varepsilon/2, \: \forall n \geq N_2
    \end{align*}

    Let $N = \max\{N_1, N_2\}$, then $n \geq N$ satisfies 
    $n \geq N_1$ and $N \geq N_2$ so 
    $$ 
        |x_n - x| + |y_n - y| < \varepsilon
    $$ 

    Notice that via the triangle inequality we get 
    $$ 
        |(x_n + y_n) - (x + y)| = |(x_n - x) + (y_n - y)| 
        \leq |x_n - x| + |y_n - y| < \varepsilon
    $$ 
    completing the proof. 
\end{proof}

\begin{thm}
    A sequence $x_n$ converges to $x$ if and only if 
    $$
        \lim \sup x_n = \lim \inf x_n = x
    $$ 
\end{thm}
We will take this theorem without proof as it requires some background
about monotone sequences and completeness which are covered 
later. 

\begin{defn}[Limit of a function]
    \label{defn:limit_function}
    Let $f: D \subset \mathbb R \to \mathbb R$, and let 
    $a$ be a limit point of $D$. 

    We say 
    $$ 
        \lim_{x \to a} f(x) = L 
    $$ 
    if for every $\varepsilon > 0$ there exists $\delta > 0$ 
    such that 
    $$ 
        0 < |x - a| < \delta \Rightarrow |f(x) - L| < \varepsilon
    $$ 
\end{defn}

Later, when we get to metric spaces again, this condition becomes 
$$ 
    d_X(x,a) < \delta \Rightarrow d_Y(f(x), f(a)) < \varepsilon
$$ 
for continuity. 

\begin{thm}[Sequential criterion]
    $$ 
        \lim_{x\to a}f(x) = L \Leftrightarrow 
        \text{for every sequence } x_n \to a \text{ with }
        x_n \neq a, f(x_n) \to L
    $$ 
\end{thm}
\begin{proof}[Proof sketch]
    We only prove $\Rightarrow$, for now. 

    Assume $\lim_{x\to a}f(x) = L$. 

    Let $x_n \to a$ with $x_n \neq a$. 

    Given $\varepsilon > 0$, choose $\delta > 0$ from the 
    definition of the limit. 

    Since $x_n \to a$ there exists $N \in \mathbb N$ such that 
    with $n \geq N$ we have 
    $$ 
        |x_n - a| < \delta 
    $$ 

    Hence for $n \geq N$, 
    $$ 
        |f(x_n) - L| < \varepsilon
    $$ 

    Thus $f(x_n) \to L$.
\end{proof}

\newpage 
\section{Completeness}
\begin{defn}[Upper Bound]
    \label{defn:upper_bound}
    A set $A \subset \mathbb R$ is bounded above if 
    there exists $M \in \mathbb R$ such that 
    $$ 
        a \leq M, \: \forall a \in A
    $$ 

    Such an $M$ is called an upper bound. 
\end{defn}

\begin{defn}[Supremum]
    \label{defn:sup}
    Let $A \subset \mathbb R$. 

    A number $s \in \mathbb R$ is the supremum of $A$ if it 
    is an upper bound of $A$ and for any 
    upper bound $u$ of $A$ we have 
    $$ 
        s \leq u
    $$  
    and we use the notation 
    $$ 
        s = \sup A
    $$ 
\end{defn}

The completeness axiom says that every nonempty subset of 
$\mathbb R$ that is bounded above has a supremum in $\mathbb R$, 
this being the distinguishing quality separating 
$\mathbb R$ from $\mathbb Q$. 

Sidenote: You can also characterize the reals 
as the \emph{unique} ordered field containing $\mathbb Q$ which 
has the least upper bound property. More precisely, every 
$\mathbb F$ with this property satisfies $\mathbb F \cong \mathbb R$.

\begin{prop}
    If $A$ has a supremum then for every $\varepsilon > 0$, 
    there exists $a \in A$ such that 
    $$ 
        s - \varepsilon < a \leq s
    $$ 
\end{prop}
\begin{proof}
    Let $\varepsilon > 0$. If no $a \in A$ existed with the 
    desired property, then $s - \varepsilon$ would be a supremum, 
    contradicting minimality of $s$.
\end{proof}
This proposition becomes useful later in many arguments. 

The infimum $\inf A$ is also something we need and classically we 
define it as being the greatest lower bound, but for 
the purposes of keeping things simple, we 
just let the infimum of a set $A$, $\inf A$, be defined as 
$$ 
    \inf A = -\sup(-A)
$$ 

\newpage 
\begin{thm}[Monotone convergence]
    Let $(x_n)$ be a monotone increasing sequence 
    (a sequence with which $x_n \leq x_{n+1}$ for every 
    $n \in \mathbb N$) which is bounded above. 

    Then $(x_n)$ converges, and 
    $$ 
        \lim x_n = \sup\{x_n : n \in \mathbb N\}
    $$ 
\end{thm}
\begin{proof}
    Let 
    $$ 
        A = \{x_n : n \in \mathbb N\}
    $$ 
    
    Since $A$ is bounded above, $A$ has some supremum $s$. 
    We claim $x_n \to s$. 

    Let $\varepsilon > 0$. 

    By the supremum property, there exists $N$ such that 
    $$ 
        s - \varepsilon < x_N < \leq s
    $$ 
    
    Since the sequence is increasing, for all $n \geq N$, 
    $$ 
        s - \varepsilon < x_n \leq s
    $$ 

    Thus 
    $$ 
        |x_n - s| < \varepsilon
    $$ 
\end{proof}

\begin{lem}
    Every cauchy sequence in $\mathbb R$ is bounded. 
\end{lem}
\begin{proof}
    Let $(x_n)$ be cauchy. 

    Choose $\varepsilon = 1$. Then there exists $N$ such 
    that 
    $$ 
        |x_n - x_m| < 1, \: \forall n,m \geq N
    $$ 

    Fix $m = N$. Then for all $n \geq N$: 
    $$ 
        |x_n| \leq |x_N| + |x_n - x_N| < |x_N| + 1
    $$ 
    
    Thus all terms are bounded. 
\end{proof}

\begin{thm}
    Every cauchy sequence in $\mathbb R$ converges. 
\end{thm}
\begin{proof}[Proof idea]
    Let $(x_n)$ be cauchy. 

    $(x_n)$ is bounded. Use the cauchy property to construct nested 
    intervals. Show the intersection of these to be nonempty 
    via completeness of $\mathbb R$. 
    $(x_n)$ will converge to a point in this intersection. 

    A bit more formally, we choose indices $n_1, n_2, \ldots$ 
    such that 
    $$ 
        |x_n - x_m| < 2^{-k}, \: \forall n,m \geq n_k
    $$ 
    and define the intervals 
    $$ 
        I_k = [x_{n_k} - 2^{-k}, x_{n_k} + 2^{-k}]
    $$ 

    Then each $I_k$ is closed and bounded with $I_{k+1} \subset I_k$.
    Completeness wil give us 
    $$ 
        \bigcap_{k \in \mathbb N} I_k \neq \emptyset
    $$ 
    
    There will be an $x$ in this set which is the limit point. 
\end{proof}

\newpage 
\section{Open and Closed Sets in Metric Spaces}
Let $X$ be a set and $A \subseteq X$. 
Intuitively, a point $x$ is either \textbf{inside of} $A$, 
\textbf{outside of} $A$, or \textbf{on the boundary} of A.  
We know what it means to not be in $A$; $a \not\in A \Leftrightarrow 
a \in A^c$. 
We also know what $a \in A$ means, but set-theoretically we don't 
have a notion of being on the "boundary" of $A$. 
We can make sense of this notion in a metric space. 

Recall that the open ball is the set 
$B(x;r) = \{z \in X : d(x,z) < r\}$. Likewise we can define 
the closed ball as follows. 

\begin{defn}[Closed Ball]
    The closed ball centered at $x \in X$ with radius $r \geq 0$ in 
    $B(x;r) = \{z \in X : d(x,z) \leq r\}$. 
\end{defn}

Let $(X,d)$ be a metric space with $A \subseteq X$. 

\begin{itemize}
    \item $x \in X$ is an interior point of $A$ if 
        $B(x;r) \subseteq A$ for some $r > 0$. 
    \item $y \in X$ is an interior point of $A$ if 
        $B(x;r) \subseteq A^c$ for some $r > 0$. 
    \item $z \in X$ is a boundary point of $A$ if it is neither of 
        the above, i.e. 
        $B(z;r) \cap A \neq \emptyset$ and $B(z;r) \cap A^c \neq  
        \emptyset$ for every $r > 0$.
\end{itemize}

Notably, every point in $X$ is one of these three. 

\begin{itemize}
    \item $A^0 = \{\text{all interior points of } A\}$
    \item $\partial A = \{\text{all boundary points of } A\}$ 
    \item $\overline A = A \cup \partial A = ((A^c)^0)^c$
\end{itemize}

\begin{prop}
    For any $A \subset X$, we have $\partial A = \partial (A^c)$.
\end{prop}

\begin{thm}
    Useful characterizations of openness: 

    $A \subseteq X$ is open if $A = A^0$

    $A \subseteq X$ is open if $A$ contains none of its boundary 
    points. 

    $A \subseteq X$ is open if $A \cap \partial A = \emptyset$

    $A \subseteq X$ is open if $\forall x \in A$ there is some 
    $r > 0$ s.t. $B(x;r) \subseteq A$ 
\end{thm}

\begin{thm}
    Useful characterizations of openness: 

    $B \subseteq X$ is closed if $B = \overline B$

    $B \subseteq X$ is closed if $A$ contains all of its boundary 
    points. 

    $A \subseteq X$ is closed if $ \partial B\subseteq B$
\end{thm}

\newpage 
\begin{prob}
    Consider $X = \mathbb R$ with the canonical metric $|\cdot|$. 
    Show that $(a,b)$ is open and $[a,b]$ is open for 
    $a \leq b \in \mathbb R$, and $(a,b]$ is 
    neither open nor closed for $a < b$.
\end{prob}
\begin{proof}
    Let $x \in (a,b)$, i.e. $a < x < b$. Take 
    \[
        r := \min\{x - a, x - b \} > 0
    \]
    Take any $y \in (x-r, x+y)$. 
    Then 
    \[
        y > x - r \geq a, \: y < x + r \leq b
    \]
    Therefore 
    \[
        (x-r, x + r) \subset (a,b)
    \]

    In other words, every $x \in (a,b)$ admits and open ball 
    contained entirely in the interval, so $(a,b)$ is open.

    Notice that $\partial(a,b) = \{a,b\}$ and that 
    $[a,b] = \partial(a,b) \cup (a,b)$ hence $[a,b]$ is the closure 
    of $(a,b)$ and thus is closed.  

    It is clear that $(a,b]$ is neither open nor closed as 
    $\partial(a,b] = \{a,b\} \not \subseteq (a,b]$ and 
    $(a,b] \cap \partial(a,b] \neq \emptyset$. 
\end{proof}

\newpage 
\section{Week 4 problem set}
\begin{prop}[Proposition 3.1.4 in Spaces]
    \label{prop:reverse_triangle}
    If $(X,d)$ is a metric space with $x,y,z \in X$, then 
    \[
        |d(x,y) - d(y,z)| \leq d(x,z)
    \]
\end{prop}
\begin{prob}
    Prove \Cref{prop:reverse_triangle}. 
\end{prob}
\begin{proof}
    Let $(X,d)$ be a metric space and recall the standard 
    triangle inequality: 
    \[
        d(x,z) \leq d(x,y) + d(y,z)
    \]
    Now observe the following rearangements: 
    \begin{align*}
        d(x,y) &\leq d(y,z) + d(x,z) \\ 
        d(x,y) - d(y,z) &\leq d(x,z) \\ 
                        &\text{and} \\ 
        d(x,y) &\leq d(y,z) + d(x,z) \\ 
        d(y,z) &\leq d(x,y) + d(x,z) \\ 
        d(y,z) - d(x,z) &\leq d(x,y) \\ 
        -d(x,z) &\leq d(x,y) - d(y,z) 
    \end{align*}

    Together: 
    \[
        |d(x,y) - d(y,z)| \leq d(x,z)
    \]
\end{proof}
\begin{prob}[3.1.6 Spaces]
    Let $(V,||\cdot||)$ be a normed space. Show that 
    it induces a norm, i.e. 
    \[
        d(x,y) := ||x-y||
    \]
    is a norm.
\end{prob}
\begin{proof}
    Let $(V,||\cdot||)$ be a normed space. 

    \textbf{Non-negativity and Identity of Indiscernibles:}

    \[
        d(x,y) = ||x-y|| \geq 0 
    \]
    since $x-y \in V$ and $||\cdot||$ is non-negative. 
    
    \[
        d(x,x) = ||x-x|| = ||0|| = 0
    \]
    Assume $d(x,y) = 0$. 
    \[
        d(x,y) = ||x-y|| = 0
    \]
    Then $x-y = 0 \Rightarrow x = y$.

    \textbf{Symmetry:}

    Recall for a norm we have $||\alpha x|| = |\alpha| ||x||$, 
    hence 
    \[
        d(x,y) = |1|||x-y|| = ||-1(x-y)|| = ||y-x|| = d(y,x)
    \]

    \textbf{Triangle Inequality:}
    \begin{align*}
        d(x,z) &= ||x-z|| = ||x - (y + y) - z|| \\ 
               &\leq ||x-y|| + ||y - z|| \\ 
               &= ||x-y|| + ||z-y|| \\ 
               &= d(x,y) + d(y,z)
    \end{align*}
\end{proof}

\begin{prob}[3.1.7 Spaces]
    Show that if $x_1, x_2, \ldots, x_n$ are points in a metric space,
    then 
    \[
        d(x_1,x_n) \leq \displaystyle\sum_{i=1}^{n-1} d(x_i, x_{i+1})
    \]
\end{prob}
\begin{proof}
    We proceed by induction on $n \in \mathbb N$. 

    \textbf{Base Case ($n=1$).}

    Clearly, 
    \[
        d(x_1, x_1) \leq d(x_1, x_1)
    \]

    \textbf{Hypothesis.}
    Now assume, for any $k \in \mathbb N$, 
    \[
        d(x_1, x_k) \leq \displaystyle\sum_{i=1}^{k-1}d(x_i, x_{i+1})
    \]

    \textbf{Induction.}
    Let $n = k+1$. 

    \begin{align*}
        d(x_1, x_n) = d(x_1, x_{k+1}) &\leq d(x_1, x_k) + 
        d(x_k, x_{k+1}) \\ 
    &\leq \left(\displaystyle\sum_{i=1}^{k-1} d(x_i, x_{i+1})\right) 
    + d(x_k, x_{k+1}) \\ 
    &= \displaystyle\sum_{i=1}^{n-1} d(x_i, x_{i+1})
    \end{align*}
    as desired. 
\end{proof}

\begin{prob}[3.2.1 Spaces]
    Assume that $(X,d)$ is a discrete metric space. Show that 
    the sequence $\{x_n\}$ converges to $a$ if and only if there is an 
    $N \in \mathbb N$ such that $x_n = a$ for all $n \geq N$. 
\end{prob}
\begin{proof}
    Let $(X,d)$ be a discrete metric space, i.e. a metric space where
    \[
        d(x,y) = 
        \begin{cases}
            0 & \text{if } x = y \\ 
            1 & \text{otherwise}
        \end{cases}
    \]

    \textbf{$\Leftarrow$.} 
    
    Assume there is some $N \in \mathbb N$ such that 
    $\forall n \geq N$, 
    \[
        x_n = a
    \]
    Then it is clear that for any $\varepsilon > 0$, 
    \[
        x_n = 0 \Rightarrow  d(x_n,a) = 0 < \varepsilon
    \]
    so $\{x_n\} \to a$. 

    \textbf{$\Rightarrow$.}

    Assume that $\{x_n\} \to a$. Then for any $\varepsilon > 0$ 
    there exists $N \in \mathbb N$ such that for $n \geq N$, then 
    \[
        d(x_n, a) < \varepsilon
    \]
    In particular, this must hold for $\varepsilon = 0.5$. 
    Notice that this requires $x_n = a$ since otherwise we would 
    have $1 < 0.5$, a contradiction. 
\end{proof}

\begin{prob}[3.2.5 Spaces]
    Let $(X,d)$ be a metric space and fix some $a \in X$. 
    Show that the function $f:X \to \mathbb R$ defined as 
    \[
        f(x) = d(x,a)
    \]
    is continuous. 
    Note: $\mathbb R$ is finite dimensional so we are free 
    to choose any metric. $d{\mathbb R}(x,y) = |x-y|$ is fine.
\end{prob}
\begin{proof}
    Let $(X,d)$ be a metric space and fix $a \in X$. 
    Let $f$ be defined as above. 

    Consider a family of sequences in $X$ such that every sequence 
    $\{x_n\}$ converges to $a \in X$. Let $\{x_n\}$ be some arbitrary
    sequence in this family.

    Then, $\forall \varepsilon > 0$ we have some natural number 
    $\mathbb N$, s.t. for any $n \geq N$,
    \[
        d(x_n, a) < \varepsilon
    \]

    Notice that 
    \[
        d(x_n,a) = |d(x_n,a) - 0| < \varepsilon
    \]
    where $\varepsilon > 0$ was arbitrary. Hence 
    $f(\{x_n\})$ converges to $0 = d(a,a) = f(a)$. 

    Thus $f$ is continuous.
\end{proof}
\begin{prob}
    Let $(X,d)$ be a metric space. Prove that every finite 
    subset of $X$ is closed. 
\end{prob}
\begin{proof}
    Recall that proposition $3.3.13$ from Spaces tells us that 
    for any finite collection $F_1, \ldots, F_n$ of closed sets, 
    their union 
    \[
        \bigcup_{i \in [n]} F_i
    \]
    is closed. 

    Consider any singleton $\{x\} \subseteq X$. It is clear that 
    $\{x\}$ is closed since $\{x\}^c$ is open. Observe that 
    the open ball $B(y;\varepsilon) \subseteq \{x\}^c$ for any 
    $y \in X \setminus \{x\}$ with $\varepsilon = d(x,y)$.
    
    Let $\{x_1,\ldots,x_n\} \subseteq X$ be any finite subset. As 
    shown above, $\{x_i\}$ is closed, and by proposition 3.3.13 
    \[
        \{x_1,\ldots,x_n\} = \bigcup_{i\in[n]} \{x_i\}
    \] 
    is closed. 
\end{proof}

\begin{prob}[3.3.13 Spaces]
    A metric space $(X,d)$ is disconnected if it is the union 
    of two non-empty, disjoint and open subsets. If it is not 
    disconnected it is connected. 
    
    a) Let $X = (-1,1) \setminus \{0\}$ and let $d$ be the usual 
    metric on $X$. Show that $(X,d)$ is disconnected. 

    b) Let $X = \mathbb Q$ and let $d$ be the usual metric again. 
    Show that $(X,d)$ is disconnected. 

    c) Assume that $(X,d)$ is a connected metric space
    and that $f: X \to Y$ is continuous and surjective. Show that 
    $Y$ is connected.
\end{prob}
\begin{proof}[Proof of (a)]
    It is clear that $(-1,0)$ and $(0,1)$ are open with respect to 
    $d(x,y) = |x-y|$ as, we can find an open ball around any 
    point in either. Since 
    \[
        X = (-1,0) \cup (0,1)
    \]
    we conclude that $X$ is disconnected. 
\end{proof}
\begin{proof}[Proof of (b)]
    Recall that $\sqrt 2 \not\in \mathbb Q$ so 
    the open subsets 
    \[
        (-\infty, \sqrt 2) \cap \mathbb Q 
        \text{ and }
        (\sqrt 2, \infty) \cap \mathbb Q 
    \]
    Both of these sets are open in $\mathbb R$ and thus they 
    are also open in $\mathbb Q$.
\end{proof}
\begin{proof}[Proof of (c)]
    Suppose, for a contradiction that we have some 
    continuous surjection $f : X \to Y$ where $X$ is connected 
    and $Y$ is not. 

    From surjection we can gleam that for any $y \in Y$ there 
    is some $x \in X$ such that $f(x) = y$. From continuity
    at every point we have that there is some 
    $\delta > 0$ for any $\varepsilon > 0$ such that
    \[
        f\left[B_X(x;\delta)\right] \subseteq B_Y(f(x);\varepsilon)
    \]
    By assumption 
    \[
        Y = O_1 \cup O_2
    \]
    for some nonempty, disjoint, open $O_1$ and $O_2$.  
    So for any point in $O_1$ or $O_2$ we have an open neighbourhood 
    surrounding it. Consider some family open sets in 
    $O_1$, $\{\omega_n\}_{n\in\mathbb N}$ such that 
    \[
        \bigcup_{n\in\mathbb N} \omega_n = O_1
    \]
    It is clear that $\omega_i \not \in O_2$ for any $\omega_i$. 
    Suppose $\omega_i$ is centered around $y_i \in Y$. By surjectivity
    we have that there are some $x_i \in X$ such that 
    the image open ball around $x_i$ goes to the open ball around 
    $y_i$. It is not hard to see that we are characterizing 
    an open set in $X$ which is mapped to $O_1$. Repeat this process 
    for $O_2$ and we will see that since there is no open ball 
    which falls in both sets, and correspondingly via 
    continuity there then is no ball in $X$ which falls in the 
    pre-images of both $O_1$ and $O_2$, hence we have partitioned 
    $X$ into two disjoint non-empty subsets. So $X$ is disconnected, 
    a catastrophic contradiction.
\end{proof}
\begin{proof}[Another attempt at a proof of (c)]
    Suppose, for a contradiction that we have a 
    continuous surjection $f: X \to Y$ where $X$ is connected and 
    $Y$ is not. 

    Let $A \subseteq X$ be a subset such that $f\mid_A : A \to Y$ 
    is a bijection. Since it is the restriction of $f$ to $A$ is 
    still continuous $f$ constitutes a homeomorphism from $A \to Y$.
    Then, the inverse $g : Y \to A$ exists, which is still continuous 
    of course. 

    Recall that a function $g$ from a metric space $Y \to A$ is 
    continuous if and only if for any $\varepsilon > 0$ we 
    have some $\delta > 0$ such that 
    \[
        g\left[B_Y(y;\delta)\right] \subseteq B_A(g(y);\varepsilon)
    \]
    for any $y \in Y$.
    By assumption, there exist $O_1$ and $O_2$ such that 
    \[
        Y = O_1 \cup O_2
    \]
    with $O_1, O_2 \neq \emptyset$ and disjoint. 
    Furthermore, $O_1$ and $O_2$ are open. 
    We now claim that $A$ is partitioned into 
    two disjoint, nonempty, open sets
    \[
        g[O_1] \text{ and } g[O_2]
    \]
    It is not hard to see that they are both open as the 
    open ball around any point in $O_1$ or $O_2$ is sent to 
    some open ball around a point in their image via continuity. 
    Furthermore it is clear that they are nonempty since 
    $g$ is a bijection and $O_1, O_2$ are nonempty. 

    Lastly, assume (for contradiction) 
    that there is some $y \in Y$ such that 
    $g(y) \in g[O_1]$ and $g(y) \in g[O_2]$, i.e. 
    they are not disjoint. 
    Then we would have $f\mid_A(g(y)) \in O_1$ and 
    $f\mid_A(g(y)) \in O_2$. Recalling that $f\mid_A \circ g = id_Y$ 
    we have that $y \in O_1$ and $y \in O_2$, but it is established 
    that no such point exists, contradicting the 
    assumption that $g[O_1] \cap g[O_2] \neq \emptyset$.

    Thus we have shown that $A$ is disconnected, but then 
    $X$ is also disconnected, a catastrophic contradiction to 
    our original assumption.
\end{proof}

\begin{prob}[3.3.13 Spaces (again)]
    A space $X$ is path connected if there is a 
    continuous $r : [0,1] \to X$ for every pair $x,y \in X$
    such that $r(0) = x$ and $r(1) = y$.

    d) Let $d$ be the usual metric on $\mathbb R^n$: 
    \[
        d(x,y) = ||x-y|| = \sqrt{\displaystyle\sum_{i=1}^{n} 
        (x_i - y_i)^2}
    \]
    Show that $(\mathbb R^n, d)$ is path-connected. 

    e) Show that every path-connected metric space is connected.
\end{prob}
\begin{proof}[Proof of (d)]
    Consider two distinct points $x,y \in \mathbb R^n$. Then 
    \[
        x = (x_1,\ldots,x_n), \ y = (y_1,\ldots,y_n)
    \]
    Consider the vector 
    \[
        (y - x) \cdot z = (y_1 - x_1, \ldots, y_n - x_n) \cdot z, \; 
        z \in [0,1]
    \]
    It is clear that 
    \[
        x + (y-x) \cdot 0 = x \text{ and } x + (y - x) \cdot 1 = y  
    \]
    So define $r: [0,1] \to X$ by 
    \[
        r(z) := x + (y-x) \cdot z
    \]
    Let $z \in [0,1]$ and fix any $z_0 \in \mathbb Z$, 
    let $\varepsilon > 0$ and choose $\delta := 
    \frac{\varepsilon}{||x-y||}> 0$. 
    Assume
    \[
        |z - z_0| < \delta 
    \]
    Then, 
    \begin{align*}
        ||r(z) - r(z_0)|| 
        &= ||(x + (y-x) \cdot z) - (x + (y-x) \cdot z_0)|| \\ 
        &= \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            (x_i - zx_i + zy_i) 
            - 
            (x_i - z_0x_i + z_0y_i)
        \right)^2
        \right)^{1/2} \\ 
        &= \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            (z_0-z)x_i + (z - z_0)y_i
        \right)^2
        \right)^{1/2} \\ 
        &= \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            (z - z_0)(y_i - x_i)
        \right)^2
        \right)^{1/2} \\ 
        &= |z - z_0| \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            y_i - x_i
        \right)^2
        \right)^{1/2} \\ 
        &= |z-z_0| \cdot ||x - y||
        < \delta \cdot ||x-y|| = \frac{\varepsilon}{||x-y||}||x-y|| 
        \\ 
        &= \varepsilon
    \end{align*}
\end{proof}

\newpage 
\section{Week 6 problem set}
\begin{prob}[Problem relating to Section 3.3]
    Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces, let $f:X\to Y$ be a continuous function, let $y\in Y$ be some given point, and consider the problem of finding an $x\in X$ such that $f(x)=y$ (that is, we wish to solve the above equation). Prove that the set of solutions of this equation is a closed subset of $X$.  

    \emph{Hint:} Phrase the question in terms of finding $f^{-1}$ of a closed set.
\end{prob}
\begin{proof}
    Apply the assumptions of the problem description.

    Let $S_y \subseteq X$ denote the set of solutions to 
    $f(x) = y \in Y$.
    Notice that $S_y$ is the set $f^{-1}[\{y\}]$. Since $\{y\}$ is 
    a singleton it is a closed set. 
    In the topological sense, if $f$ is continuous then the preimage 
    of every closed set in $Y$ is closed in $X$. 
    This would complete the proof, but let us give an analytical 
    way of doing it instead. 

    Once again let $S_y \subset X$ denote the set of $x \in X$ such 
    that $f(x) = y \in Y$. Let $\{x_n\}$ be some sequence in 
    $S_y$ such that $x_n \to x$ in $X$. Now we need to show 
    that $x \in S_n$, i.e. $f(x) = y$. Since $x_n \in S_y$ 
    we have that (for every $n \in \mathbb N$) 
    \[
        f(x_n) = y
    \]
    $f$ is continuous so via sequential continuity we get 
    \[
        f(x_n) = f(x)
    \]
    i.e. 
    \[
        f(x) = y
    \]
    Thus $x \in S_y$. 
    Since $\{x_n\}$ was an arbitrarily chosen convergent sequence 
    in $S_y$ and we found that $x_n \to x \in S_y$ we conclude 
    that $S_y$ contains all it's limit points. In other 
    words $S_y$ is closed. 
\end{proof}
\begin{prob}
    Prove that $(\mathbb{Z},d)$, where $d(x,y)=|x-y|$, is complete.  
    \emph{Hint:} What does it mean for a sequence in $(\mathbb{Z},d)$ to converge or to be Cauchy?
\end{prob}
\begin{proof}
    Let $\{x_n\}$ be a cauchy sequence in $\mathbb Z$. 
    Then, for every $\varepsilon > 0$ there is some $N \in \mathbb N$
    s.t. 
    \[
        |x_n - x_m| < \varepsilon
    \] 
    for every $n,m \geq N$. 
    Notice that we then require $x_n = x_m$ for all $n,m \geq N$ 
    since if that weren't the case we would have 
    $0 < \varepsilon := 0.5 < 1 \leq |x_n - x_m|$. Thus 
    every cauchy sequence in $\mathbb Z$ will necessarily settle 
    at some $x \in \mathbb Z$ and be constant. In other words, 
    $\{x_n\} \to x \in \mathbb Z$, as desired.  
\end{proof}
\begin{prob}[Problem 3.3.3 Spaces]
    Assume that $F$ is a nonempty, closed and bounded 
    subset of $\mathbb R$ with the usual metric. Show that 
    $\inf F \in F$ and $\sup F\in F$. Give an example of a 
    bounded, but not closed set such that it contains it's supremum
    and infinmum.
\end{prob}
\begin{proof}
    Suppose $\emptyset \neq F \subseteq \mathbb R$ with 
    $F$ closed and bounded. 

    Recall that since $F$ is bounded there is some finite 
    $r > 0$, $x \in F$ such that 
    \[
        F \subseteq (x-r,x+r)
    \]
    Recall that for any nonempty subset of $\mathbb R$ there 
    exists a least upper bound and greates lower bound, i.e.
    $\inf F \in \mathbb R$ and $\sup F \in \mathbb R$. 

    Let $\{x_n\}$ be a sequence in $F$ such that $\{x_n\} \to \sup F$.
    By closedness $\sup F \in F$. Apply this same reasoning to 
    the infimum to get the desired result. Notice that we required 
    boundedness as, if $F$ wasn't bounded above and below we 
    might have had $\inf F = -\infty$ or $\sup F = \infty$. In 
    that case we couldn't have constructed sequences converging 
    to these points.

    Let $F = [0,1] \setminus \{\frac{1}{2}\}$. Clearly not closed 
    since any sequence converging to $1/2$ contradicts it being 
    closed. It is bounded above and below and $\inf F = 0 \in F$ 
    and $\sup F = 1 \in F$. 
\end{proof}
\begin{prob}[Problem 3.3.11 Spaces]
    Prove Proposition 3.3.12. Find an infinite collection of open 
    sets whose intersection is closed. 
\end{prob}
\begin{prop}[Proposition 3.3.12 from Spaces]
    Let $(X,d)$ be a metric space. 

    a) If $\mathcal G$ is a finite or infinite collection of 
    open sets, then 
    \[
        \bigcup_{G \in \mathcal G}G 
    \]
    is open.

    b) If $G_1, \ldots, G_n$ is a finite collection of open sets 
    then 
    \[
        \bigcap_{i=1}^n G_i
    \]
    is open.
\end{prop}
\begin{proof}[Proof of (a)]
    Consider a (potentially infinite) family 
    $\mathcal G = \{G_1,G_2,\ldots\}$ of open sets. 
    Define 
    \[
        \Gamma := \bigcup_{G \in \mathcal G} G
    \]
    Take any arbitrary $x \in \Gamma$. Then there is some 
    $G_i$ such that $x \in G_i$. 
    As $G_i$ is open there is some $r\in \mathbb R^+$ with 
    \[
        B(x;r) \subseteq G_i \subseteq \Gamma
    \]
    Hence $\Gamma$ is open. 
\end{proof}
\begin{proof}[Proof of (b)]
    Let $\mathcal G = \{G_i\}_{i \in [n]}$ be a finite family of 
    open sets.  
    Define 
    \[
        \Gamma := \bigcap_{i\in[n]} G_i
    \]
    Suppose $x \in \Gamma$. Then $\bigwedge_{i=1}^n x \in G_i$ and 
    for each $G_i$ there is some $r_i > 0$ such that 
    \[
        B(x;r_i) \subseteq G_i
    \]
    Then 
    \[
        B(x;\min\{r_i : 1 \leq i \leq n\}) = 
        \bigcap_{i=1}^n B(x;r_i) \subseteq \bigcap_{i \in [n]} G_i 
        = \Gamma
    \]
    so $\Gamma$ is open.
\end{proof}
\begin{ex}[Counter example for infinite intersection.]
    Consider the metric space $(\mathbb R, |\cdot|)$. 
    Consider the following infinite family of open sets 
    \[
        \left\{ 
            (-1/n,1/n)
        \right\}_{n \in \mathbb N}
    \]      
    Clearly, 
    \[
        \bigcap_{n\in\mathbb N} (-1/n,1/n) = \{0\}
    \]
    which is closed in $\mathbb R$.
\end{ex}
\begin{prob}
    prob
    Consider $X=\mathbb{R}$ with the canonical metric $d(x,y)=|x-y|$. The \emph{support} of a function $f:\mathbb{R}\to\mathbb{R}$ is the set of points $x$ where $f(x)\neq 0$. Prove that the support of a continuous function is always open.  
    \emph{Note:} In the literature, the "support" of $f$ is usually defined to be the closure of the above set, which is of course closed, not open.
\end{prob}
\begin{proof}
    Let $f:\mathbb R\to\mathbb R$ be continuous and let
    \[
        \Omega := \{x\in\mathbb R : f(x)\neq 0\}.
    \]
    Suppose, for a contradiction, that $\Omega$ is not open. 
    Then there exists
    $x\in\Omega$ such that for every $r>0$ there is some 
    $y\in(x-r,x+r)$ with
    $f(y)=0$.

    Since $f$ is continuous at $x$, for $\varepsilon := |f(x)| > 0$ 
    there exists
    $\delta>0$ such that
    \[
        |f(y)-f(x)|<\varepsilon \quad \text{whenever } |y-x|<\delta.
    \]
    By assumption, there exists $y\in(x-\delta,x+\delta)$ 
    with $f(y)=0$.
    Then
    \[
        |f(x)| = |f(x)-f(y)| < |f(x)|,
    \]
    a contradiction. Hence $\Omega$ is open.
\end{proof}
\begin{prob}
    Show that the equation $\cos t = 2t$ has a unique solution.  
    \emph{Hint:} Formulate the problem as finding the fixed point of a function $f$.
\end{prob}
\begin{proof}
    Banach's fixed-point theorem tells us that for some complete 
    metric space $X$, a contraction $F:X\to X$ will have a unique 
    $t \in X$ such that 
    \[
        t = F(t)
    \]
    Let $F: \mathbb [0,\pi/2] \to \mathbb [0,\pi/2]$ be defined by 
    \[
        F(t) := \frac{1}{2}\cos t
    \]
    Clearly, $F(t) = t$ if and only if $\cos t = 2t$. 
    Furthermore, as a closed bounded subset of a compelte emtric  
    space,  $([0,\pi/2], |\cdot|_{[0,\pi/2]})$ is complete.  
    Now all we need is to show that 
    $F$ constitutes a contraction on $\mathbb R$. 
    Notice that 
    \[
        \frac{1}{2}\cos(t) \in [0,1/2], \: t \in [0,\pi/2]
    \]
    so $F$ ceirtanly constitutes a contraction. Thus 
    by Banach's fixed point theorem there is a unique 
    point $t \in [0,\pi/2]$ such that $t = F(t)$. $t$ constitutes 
    the unique solution to 
    \[
        \cos(t) = 2t
    \]
\end{proof}

\newpage 
\section{3.4 \& 3.5}
\begin{prop}
    Let $(X,d)$ be a metric space. Let $f : X \to X$ be 
    a contraction. Then $f$ is continuous.
\end{prop}
\begin{proof}
    Let $f : X \to X$ be a contraction. In other words, for 
    some $\omega \in (0,1)$, let 
    $f$ satisfy  
    \[
        d(f(x), f(y)) \leq \omega d(x,y), \: \forall x,y \in X
    \]
    Let $\varepsilon > 0$. 
    Define $\delta = \frac{\varepsilon}{\omega}$.
    Suppose $d(x,y) < \delta$. Then 
    \[
        d(f(x),f(y)) \leq \omega d(x,y) < \omega \cdot \delta 
        = \varepsilon
    \]
\end{proof}

Recall that completeness is a very usefull property as if a 
sequence seems to converge then it does converge, and to a 
point in the space. However, sometimes it is hard to 
show that a sequence is cauchy. 
It would be nice to substitute this requirement to get 
some other way of showing convergence of sequence in a space. 
We could require that every sequence converges, but that 
is a ridiculously strict requirement and false most of the time. 
So instead, we require all sequences to have convergent subseqneces. 

Recall the definition of a subsequence: 
\begin{defn}[Subsequence]
    Let $\{x_n\}_{n\in \mathbb N}$ be a sequence. A subsequence is 
    a sequence of the form $\{x_{n(k)}\}_{k\in\mathbb N}$, 
    where $n(k) \in \mathbb N$ and 
    \[
        n(1) < n(2) < n(3) < \cdots
    \]
\end{defn}
Useful note: $n(k) \geq k$.
\begin{prop}
    Let $(X,d)$ be a metric space. If $\{x_n\}_n$ converges, then 
    all possible subsequences converge, and the limit is the 
    same. 
\end{prop}
\begin{proof}
    Let $\varepsilon > 0$, let $N \in \mathbb N$ be such that 
    $d(x_n, x) < \varepsilon$. Then $n(k) \geq n \geq N$
    so also 
    \[
        d(x_{n(k)}, x) < \varepsilon
    \]
\end{proof}
\begin{defn}[Compactness]
    A metric space $(X,d)$ is said to be \emph{compact} if every 
    sequence $\{x_n\}_n$ has a convergent subsequence 
    $\{x_n(k)\}_k$.
\end{defn}
\begin{defn}
    A subset $K \subseteq X$ of a metric space $(X,d)$ 
    is compact if $(K,d)$ is compact. 
\end{defn}
\begin{thm}
    Let $(X,d)$ be a metric space. If $K \subseteq X$ is finite 
    then $(K,d)$ is compact.
\end{thm}
\begin{proof}
    Let $\{x_n\}_{n\in\mathbb N}$ be a sequence in 
    $K = \{k_1, k_2, \ldots, k_m\}$. 
    As $\{x_n\}_n$ is infinite, there must be at least one 
    element $k_i$ where $x_j = k_i$ for infinitely many 
    $j \in \mathbb N$. 
    Then we can pick out indices such that 
    $\{x_n(p)\}_{p\in\mathbb N}$ is a constant sequence for 
    some $k_i \in K$ and thus convergent.
\end{proof}
\begin{thm}
    Let $(X,d)$ is compact. Then $(X,d)$ is complete. 
\end{thm}
\begin{proof}
    Let $\{x_n\}_n$ be cauchy. As $(X,d)$ is compact there exists 
    some convergent $\{x_{n(k)}\}_k$ which converges to $x \in X$.  
    For $\varepsilon > 0$, let $N_1 \in \mathbb N$ be s.t. 
    \[
        d(x_{n(k)}, x) < \varepsilon, \: n \geq N_1
    \]
    and let $N_2 \in \mathbb N$ s.t. 
    \[
        d(x_n, x_m) < \varepsilon, \: n,m \geq N_2
    \]
    Let $N = \max\{n(N_1),N_2\}$. If $m \geq N$ then 
    \[
        d(x_m, x) \leq \underset{<\varepsilon}{d(x_m, x_{n(m)})}  
        + \underset{<\varepsilon}{d(x_{n(m)}, x)} < 
        2\varepsilon
    \]
    Hence $\{x_n\}_n$ converges to $x \in X$.
\end{proof}
\begin{thm}
    If $K \subseteq X$ is compact then it is closed and bounded. 
\end{thm}
\begin{proof}
    Let $K \subseteq X$ be compact.

    \textbf{Closed.} 

    Let $\{x_n\}_n$ be a sequence in $K$ converging to $x \in X$. 
    By compactness we can find a subsequence $\{x_{n(k)}\}_k$ 
    converging to some $y \in K$. Then $x = y \in K$, as the 
    subsequence converges to the same value. 

    \textbf{Bounded.}

    Assume $K$ is not bounded. Fix $\overline x \in X$. Then 
    for every $n \in \mathbb N$, there is some $x_n \in K$ with 
    \[
        d(x_n, \overline x) \geq n
    \]
    Let $\{x_{n(k)}\}_k$ be a convergent subsequence of $\{x_n\}_n$.
    Then 
    \[
        n(k) \leq d(x_{n(k)}, \overline x) 
        \underset{k \to \infty}{\to} d(x,\overline x)
    \]
    In other words, a value which tends to infinity is less than 
    a fixed value. 
\end{proof}
\begin{prop}
    Let $X = \mathbb R^n$, $d(x,y) = ||x-y||$ 
    (all norms are equivalent in $\mathbb R^n$). 
    Let $K \subseteq \mathbb R^n$. Then 
    \[
        K \text{ is compact}
        \Leftrightarrow 
        K \text{ is closed and bounded}
    \]
\end{prop}
\begin{proof}
    The l2r direction is already covered so we tackle the other 
    way. 

    Let $K$ be closed and bounded. Let $\{x_n\}_n$ be a sequence 
    in $K$. 
    Then $\{x_n\}_n$ is bounded, so by Bolzano-Weierstrass, there 
    is a convergent subsequence $\{x_{n(k)}\}_k$ converging to 
    some $x \in \mathbb R^n$. Since $K$ is closed $x \in K$. 
    We conclude that $K$ is compact. 
\end{proof}
\begin{thm}
    Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces with 
    $f:X\to Y$ continuous. If $K \subseteq X$ is compact then 
    $f[K]$ is, also.
\end{thm}
\begin{thm}
    If $(X,d)$ is compact and $f : X \to \mathbb R$ continuous. 
    Then $f$ attains a minimum and maximum.
\end{thm}

\begin{defn}
    Let $(X,d)$ be a metric space. A set $K \subseteq X$ is 
    \emph{totally bounded} if $\forall \varepsilon > 0$, 
    there exists finitely many points $x_1,\ldots,x_n \in K$ 
    such that 
    \[
        K \subseteq \bigcup_{i=1}^n B(x_i;\varepsilon)
    \]
\end{defn}
In other words, we say $K$ is totally bounded if we can find 
finitely many open balls which cover it for any 
radius $\varepsilon$. This sounds a lot like the topological 
definition of compactness (Every open cover has a finite subcover).
What we have here is a stronger property than meere boundedness. 
\begin{lem}
    Every compact set is totally bounded.
\end{lem}
\begin{proof}
    Let $K \subseteq X$ be a compact subspace of a metric 
    space $(X,d)$, and assume it is not totally bounded.   
    So $K$ compact with 
    \[
        K \not\subseteq \bigcup_{i=1}^n B(x_i;\varepsilon)  
    \]
    for any choice of $x_1, \ldots,x_n$ for some $\varepsilon$.
    Pick any $x_1 \in K$. Then $K \not\subseteq B(x_1;\varepsilon)$,
    so there is some $x_2 \in K \setminus B(x_1;\varepsilon)$.
    Iteratively pick $x_1,\ldots,x_n$, pick any 
    $x_{n+1} \in K \setminus \bigcup_{i=1}^n B(x_i;\varepsilon)$. 
    Note: $d(x_n, x_m) \geq \varepsilon$ for any $x \neq m$. 
    Then $\{x_n\}_n$ is a sequence in $K$, so has convergent 
    subsequence with limit $x \in K$. But then 
    $\varepsilon \leq d(x_n,x) + d(x,x_m) 
    \underset{x,m \to \infty}{\to} 0$.
\end{proof}

\begin{defn}
    Let $(X,d)$ be a metric space. A set $B \subseteq X$ is 
    separable if there exists a dense, countable set 
    $D \subseteq B$.
\end{defn}
\begin{ex}
    \begin{itemize}
        \item $\mathbb R$ is separable ($\mathbb Q \subseteq 
            \mathbb R$)
        \item Any subset of $\mathbb R$ is separable 
        \item $B_1, B_2, \ldots$ separable, then 
            \[
                \bigcup_{i\in\mathbb N} B_i
            \]
            is, also 
        \item $\ell^p(\mathbb R)$ is separable for all 
            $p < \infty$, but not $p = \infty$
    \end{itemize}
\end{ex}
\begin{thm}
    Let $(X,d)$ be a complete metric space, $K \subseteq X$. 
    \[
        K \ \text{compact} \Leftrightarrow K \ \text{totally bounded}
    \]
\end{thm}
\begin{thm}
    Every compact set is separable.
\end{thm}
\newpage 
\section{3.6 - Compactness IV}
\begin{defn}
    Let $(X,d)$ be a metric space and let $K \subseteq X$. 
    An \emph{open covering} of $K$ is a family of open sets 
    $\mathcal F$ satisfying 
    \[
        K \subseteq \bigcup_{\mathcal O \in \mathcal F} \mathcal O
    \]
\end{defn}
\begin{defn}
    A set $K \subseteq X$ has the open covering property if 
    for any open covering $\mathcal F$ of $K$, 
    there exists $\mathcal O_1,\ldots,\mathcal O_n \in \mathcal F$
    such that $\{\mathcal O_1,\ldots, \mathcal O_n\}$ is an 
    open covering of $K$.
\end{defn}
\begin{thm}
    A set $K \subseteq X$ is compact if and only if it has 
    the open covering property. 
\end{thm}
This is a very powerful classification of compactness and is the 
one you typically first encounter in a topology course. 
Notice that we don't need to assume completeness of $X$, 
closedness of $K$ (as that comes for free), etc. 

\newpage 
\section{4.1 - Models of Continuity}
\begin{defn}
    A function $f : X \to Y$ is 
    \begin{itemize}
        \item continuous at $x$ if $\forall \varepsilon > 0, \:
            \exists \delta > 0$ such that 
            \[
                d_Y(f(x), f(y)) < \varepsilon
            \]
            for every $y \in X$ satisfying $d_X(x,y) < \delta$.
        \item continuous if it is continuous at all 
            $x \in X$.
        \item uniformly continuous if 
            $\forall \varepsilon > 0, \: \exists \delta > 0$ s.t. 
            \[
                d_X(x,y) < \delta \Rightarrow d_Y(f(x),f(y))
            \]
            $\forall x,y \in X$.
        \item Lipschitz continuous if $\exists C > 0$ s.t. 
            \[
                d_Y(f(x),f(y)) < C d_x(x,y), \ \forall x,y \in X
            \]
    \end{itemize}
    with each subsequent property implying the one before it. 
\end{defn}
\begin{defn}
    Denote 
    \[
        C(X,Y) = \{\text{all continuous} \ f:X\to Y\}
    \]
    \[
        C(X) = C(X,\mathbb R)
    \]
\end{defn}
\begin{lem}
    If $f:A \to \mathbb R$ ($A \subseteq \mathbb R$) satisfies 
    $|f'(x)| \leq M, \: \forall x \in A$, then $f$ is 
    Lipschitz with constant $M$.
\end{lem}
\begin{lem}
    If $f : [a,b] \to \mathbb R$ is continuously differentiable, 
    then it is Lipschitz.
\end{lem}
\begin{thm}
    Let $f : X \to Y$ be continuous and $(X,d_X)$ compact. 
    Then $f$ is uniformly continuous.
\end{thm}

\newpage 
\section{Problems from week of 9/2 to 15/2}
\begin{prob}[Problem 5, Spaces p.67]
    Let $(X,d)$ be a metric space. For a subset $A \subseteq X$, 
    let $\partial A$ denote the set of all boundary points of $A$. 
    Recall that the closure of $A$ is $\overline A = A 
    \cup \partial A$. 

    \medskip

    a) A subset $A$ of $X$ is called \emph{precompact} if 
    $\overline A$ is compact. Show that $A$ is precompact if 
    and only if all sequences in $A$ have a convergent subsequence. 

    \medskip 

    b) Show that a subset of $\mathbb R^m$ is precompact if 
    and only if it is bounded. 
\end{prob}
\begin{proof}[Proof of (a)]
    Notice that what we're really saying here is that 
    $A$ is precompact if and only if $A$ is compact. 

    By an earlier theorem we have that if $A \subseteq X$ is 
    compact then it is closed and bounded. Namely 
    $A$ is closed so $A = \overline A$. Thus it is clear to 
    see that $A$ is precompact if and only if it is compact. 
\end{proof}
\begin{proof}[Proof of (b)]
    By an earlier proposition we have that a $A \subseteq \mathbb R^m$
    is compact if and only if it is closed and bounded. As we 
    saw in (a) we know that $A$ is precompact if and only 
    if it is compact. 
\end{proof}
\begin{prob}[Problem 6, Spaces p.67]
    Assume that $(X,d)$ is a metric space and that 
    $f : X \to [0,\infty)$ is continuous. Assume that for each 
    $\varepsilon > 0$, there is a compact set $K_\varepsilon 
    \subseteq X$ such taht $f(x) < \varepsilon$ when 
    $x \not\in K_\varepsilon$, Show that $f$ has a maximum point.
\end{prob}
\begin{proof}
    If $f \equiv 0$, then $f$ trivially attains its maximum.
    Assume therefore that there exists $x_0 \in X$ such that
    $f(x_0) > 0$.

    Let
    \[
        \varepsilon := \frac{1}{2} f(x_0) > 0.
    \]
    By assumption, there exists a compact set
    $K_\varepsilon \subseteq X$ such that
    \[
        f(x) < \varepsilon \quad \text{for all } x \notin K_\varepsilon.
    \]

    Since $f$ is continuous and $K_\varepsilon$ is compact, the
    restriction
    \[
        f\bigm|_{K_\varepsilon} : K_\varepsilon \to [0,\infty)
    \]
    attains a maximum. Let $x^* \in K_\varepsilon$ be such that
    \[
        f(x^*) = \max_{x \in K_\varepsilon} f(x) =: M.
    \]
    Note that
    \[
        M \ge f(x_0) > \varepsilon.
    \]

    Now let $x \in X$ be arbitrary. If $x \in K_\varepsilon$, then
    $f(x) \le M$. If $x \notin K_\varepsilon$, then
    \[
        f(x) < \varepsilon < M.
    \]
    Hence in all cases,
    \[
        f(x) \le M = f(x^*).
    \]

    Therefore $f$ attains its maximum at $x^*$.
\end{proof}

\end{document}
