\input{preamble.tex}

\title{\huge{Real Analysis}}
\author{\LARGE{Thobias Høivik}}
\date{\Large{Spring 2026}}

\begin{document}
\maketitle

\newpage
\tableofcontents

\newpage
\section{Introduction}
The following is intended for anyone who stumbles over these notes. 
This is intended to be my personal notes in real analysis. 
I will hopefully be attending MAT2400 Real Analysis at 
the University of Oslo in the spring of 2026. However, 
as I am not a program student at this institution, but 
just someone who takes individual courses there 
of my own volition, I do not and cannot attend lectures and 
therefore I have to learn the material on my own. 
As far as I understand, while this course is called Real Analysis, 
it is a bit different than a first course from what I understand. 
The earlier exams give a hint of functional analysis and 
also include topics such as fourier analysis, meassure- and integration
theory among other things. Thus the different supplementary 
coursematerial I will use to aid myself in learning the content 
of this course will most likely be a bit scattered and all over the 
place, which these notes will undoubtedly reflect. I will 
do my best to keep things organized for my own sake, but keep 
this in mind if you are someone who intends to use these 
notes to learn Real Analysis. 

\newpage 
\section{Basic Banch Space theory}
The following section of notes is derived from the first video 
in the lecture series MIT 18.102 Introduction to Functional 
Analysis, Spring 2021 (found on youtube). 

\begin{defn}[Vector Space]
    \label{defn:vector_space}
    A vector space $V$ over a field $\mathbb F$ is a nonempty 
    set of elements called "vectors" together with 
    a binary operation $+$ on $V$ and a binary function 
    $\cdot$ which maps elements of $V, \mathbb F$ to $V$ 
    satisfying: 

    \begin{enumerate}
        \item Associativity of vector addition: 
            $$ 
                u + (v+w) = (u+v)+w, \forall u,v,w \in V
            $$
        \item Commutativity of vector addition: 
            $$ 
                u + v = v + w, \forall u,v \in V
            $$ 
        \item Identity element: 
            $$ 
                \exists 0 \in V : v + 0 = 0 + v = v, \forall v \in V
            $$ 
        \item Each $v \in V$ has an inverse $-v$ under the 
            vector-addition operation.
        \item Scalar multiplication is compatible with field 
            multiplication: 
            $$ 
                a(bv) = (ab)v
            $$ 
            where $a,b \in \mathbb F$ and $v \in V$. 
        \item The multiplicative identity $1 \in \mathbb F$ 
            satisfies: 
            $$ 
                1v = v, \forall v \in V
            $$ 
        \item Distributivity of scalar multiplication with respect 
            to vector addition: 
            $$ 
                a(u+v) = au + av
            $$ 
            where $a \in \mathbb F$ and $u,v \in V$. 
        \item Distributivity of scalar multiplication with 
            respect to field addition: 
            $$ 
                (a+b)v = av + bv
            $$ 
            where $a,b \in \mathbb F$ and $v \in V$. 
    \end{enumerate}

    When proving that something is a vector space, most 
    of these follow naturally from showing closure under 
    addition and scalar multiplication and those two properties, 
    are generally enough to show that it is indeed a vector space. 

    A subspace $U$ of $V$ is a set $U \subseteq V$ which is also 
    a vector space. It is enough to show that $U \subseteq V$ and 
    that it is closed under the two operations. 
\end{defn}

\newpage 
Some typical examples of vector spaces are 
$\mathbb F^n$ where $\mathbb F$ is the reals or the complex 
numbers. We also have spaces like the space of real polynomials 
of degree $\leq n$, i.e. $\mathcal P_n = 
\{\sum_{i=0}^n \alpha_i x^i : \alpha_i \in \mathbb R\}$, 
which is itself a subspace of the space of continuous real-valued 
functions $C(\mathbb R)$. 

So $\mathbb R^2$ and $C(\mathbb R)$ 
are both vector spaces over $\mathbb R$, but 
they have one really big difference, that being the dimension. 

\begin{defn}
    \label{defn:linear_independence}
    Let $V$ be a vector space. A set $\{v_1,\ldots, v_n\} \subseteq V$
    is linearly independent if  
    $$ 
        \displaystyle\sum_{i=1}^n \alpha_i v_i = 0 
        \Leftrightarrow \alpha_1 = \dots = \alpha_n = 0 \in \mathbb F
    $$ 

    Note: the right-to-left direction of this implication is 
    always true. 
\end{defn}

The two spaces discussed above are different in dimension, 
$\mathbb R^2$ being $2$-dimensional and the other being 
infinite-dimensional. 
One definition of finite-dimensional is that every linearly 
independent set in the space is finite. 
I however like the definition using bases more. 
Both of these definitions are equivalent. 

We won't give a rigorous definition of a basis, but in short 
a basis of $V$ is a linearly independent set of vectors which spans 
$V$, i.e. every vector in $V$ can be expressed as a linear combination
of basis-vectors. If the basis is finite then $V$ 
is finite dimensional. Moreover, if the basis is finite then the 
dimension of $V$ is the number of basis-vectors. Note that 
if a finite dimensional space $V$ has a basis with $n$ elements 
then every basis of $V$ has $n$ elements. A space is  
infinite-dimensional if no finite set of linearly independent vectors 
spans the space. 

\newpage 
\subsection{Norms and Metrics}

\begin{defn}[Norm]
    \label{defn:norm}
    Let $V$ be a vector space. 
    A norm $|| \cdot || $ is a function 
    from $V \to [0,\infty)$ satisfying: 
    \begin{enumerate}
        \item $|| v || = 0$ if and only if 
            $v = 0$. 
        \item $|| \alpha v || = |\alpha| \cdot ||v||$ where 
            $\alpha$ is an element of the ground field. 
        \item $||v + w|| \leq ||v|| + ||w||$.
    \end{enumerate}
    
    The tuple $(V, ||\cdot||)$ is called a normed space. 
\end{defn}

\begin{ex}
    \label{ex:lp_norms}
    $||x||_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}$ defines 
    a norm on $\mathbb R^n$.

    In fact it constitutes a norm on $\mathbb C^2$ as well. 
    Formally, if we take $\mathbb F = \mathbb R$ or  
    $\mathbb F = \mathbb C$ the p-norm of a vector 
    $v \in \mathbb F^n$ ($p \in [1,\infty]$) is
    $$ 
        ||v||_p := 
        \begin{cases}
            \left(\displaystyle\sum_{i=1}^n |v_i|^p\right)^{1/p} & 
            p < \infty\\ 
            \max_{i=1,\dots,n}|v_i| & p = \infty
        \end{cases}
    $$ 
\end{ex}

Norms give us a notion of the "length" of a vector.  
Now all we need to do analysis on spaces is a notion of 
distance. Intuitively, norms already give us a notion of 
distance from $0$. 

\begin{defn}
    \label{defn:metric}
    Let $X$ be a set. 

    A metric is a function 
    $d:X^2 \to [0,\infty)$ satisfying: 
    \begin{enumerate}
        \item $d(x,y) = 0$ if and only if $x = y$. 
        \item $d(x,y) = d(y,x)$. 
        \item $d(x,z) \leq d(x,y) + d(y,z)$. 
    \end{enumerate}
\end{defn}

The metric gives us a notion of distance. 
In a typical first course in analysis where we work on 
the reals, $d(a,b) = |a - b|$ is the metric we deal with. 

\newpage 
\begin{prop}
    Let $V$ be a normed space with norm $||\cdot||$. 
    Then we can define the distance (a metric) between two vectors 
    by 
    $$ 
        d(x,y) := \left|\left| x - y \right|\right|
    $$ 

    In other words you can define a metric in terms of the norm 
    in any normed space. This metric is usually refered to 
    as the metric induced by the norm. 
\end{prop}

We won't provide a proof of this as it's fairly intuitive. 
Now we can get a sense of convergence and continuity in 
vector spaces by saying that a sequence $\{a_n\}_{n \in \mathbb N}$
converges to a value $a$ if 
$$ 
    \forall \varepsilon > 0, \exists N \in \mathbb N : 
    n \geq N \Rightarrow ||a_n - a || < \varepsilon 
$$ 
and a linear transformation (look up definition if necessary) 
$T \in \mathcal L(U,V)$ is (uniformly) continuous if 
$$ 
    \forall \varepsilon > 0, \exists \delta > 0 : 
    ||x - y||_U < \delta \Rightarrow 
    ||Tx - Ty||_V < \varepsilon
$$ 
for every $x,y \in U$. Notice that if you replace $||x-y||$ with 
$d(x,y)$ it looks like the standard definitions in terms 
of metric spaces. 

\newpage 
\subsection{Banach Spaces}
\begin{defn}[Banach Space]
    \label{defn:banach_space}
    A normed space $V$ is a Banach Space if it is 
    complete with respect to the metric induced by the norm, meaning
    that every cauchy sequence converges to a value in the 
    space. 
\end{defn}

\begin{ex} 
    $\mathbb R^n$ or $\mathbb C^n$ form Banach Spaces 
    with respect to the $\ell^p$ norms (see \Cref{ex:lp_norms}).
\end{ex}

\begin{thm}
    If $X$ is a complete metric space, then 
    $C_\infty(X)$ is a Banach Space. 
\end{thm}

Recall that $C_\infty(X)$ is the space of bounded continuous 
functions on $X$.

\begin{proof}
    We show that every Cauchy sequence in $C_\infty(X)$ converges 
    to an element
    of $C_\infty(X)$.

    Let $\{u_n\}_{n=1}^\infty \subseteq C_\infty(X)$ be a Cauchy 
    sequence with
    respect to the supremum norm. Then for every $\varepsilon > 0$ 
    there exists
    $N \in \mathbb{N}$ such that
    \[
        \|u_n - u_m\|_\infty < \varepsilon \quad \text{for all } 
        n,m \ge N.
    \]
    Equivalently,
    \[
        |u_n(x) - u_m(x)| < \varepsilon
        \quad \text{for all } x \in X \text{ and all } n,m \ge N.
    \]

    Fix $x \in X$. Then $\{u_n(x)\}_{n=1}^\infty$ is a 
    Cauchy sequence in
    $\mathbb{R}$ (or $\mathbb{C}$), since
    \[
        |u_n(x) - u_m(x)| \le \|u_n - u_m\|_\infty.
    \]
    Because $\mathbb{R}$ (or $\mathbb{C}$) is complete, the limit
    \[
        u(x) := \lim_{n\to\infty} u_n(x)
    \]
    exists. This defines a function $u : X \to \mathbb{R}$.

    We now show that $u_n \to u$ uniformly on $X$. Let 
    $\varepsilon > 0$ and
    choose $N$ such that $\|u_n - u_m\|_\infty < \varepsilon$ 
    for all $n,m \ge N$.
    Fix $n \ge N$ and $x \in X$. Taking the limit $m \to \infty$ gives
    \[
        |u_n(x) - u(x)|
        = \lim_{m\to\infty} |u_n(x) - u_m(x)|
        \le \varepsilon.
    \]
    Since $x \in X$ was arbitrary, it follows that
    \[
        \|u_n - u\|_\infty \le \varepsilon \quad \text{for all } 
        n \ge N.
    \]
    Thus $u_n \to u$ uniformly on $X$.

    Since each $u_n$ is bounded and the convergence is uniform, 
    the limit
    function $u$ is bounded. Moreover, since each $u_n$ 
    is continuous and
    uniform limits of continuous functions are continuous, 
    $u$ is continuous
    on $X$.

    Therefore $u \in C_\infty(X)$ and $\{u_n\}$ converges to $u$ in the
    supremum norm. Hence $C_\infty(X)$ is complete, 
    and thus a Banach space.
\end{proof}

\newpage 
\section{A step back into Calculus Theory}
The following section is largely in accordance with 
chapter 2 of Lindstrøm's Spaces: An Introduction 
To Real Analysis. 

\begin{defn}[Limit of a sequence]
    \label{defn:limit_sequence}
    Let $(x_n)$ be a sequence of real numbers and $x \in \mathbb R$. 

    We say 
    $$ 
        x_n \to x
    $$ 
    if for every $\varepsilon > 0$, there exists a natural number 
    $N$ such that 
    $$ 
        |x_n - x| < \varepsilon, \; \forall n \geq N
    $$ 
\end{defn}
This is among the most important definitions in a first 
course in Real-Analysis.   
Intuitively what it captures is the sense of being able 
to get arbitrarily close to a value. 
We will all be familiar with examples from 
calculus like $\lim_{n\to\infty} \frac{1}{n} = 0$. 

\begin{thm}
    \label{thm:limit_unique}
    If a sequence converges, then its limit is unique. 
\end{thm}
\begin{proof}
    Suppose, for a contradiction, that we have some sequence 
    $(x_n)$ with 
    $$ 
        x_n \to x \text{ and } x_n \to y
    $$ 
    of course with $x \neq y$.

    $x_n$ converges so we can choose any $\varepsilon > 0$ 
    for the condition in \cref{defn:limit_sequence} to hold. 

    Consider the case of $\varepsilon = \frac{|x-y|}{2}$. 
    $\varepsilon > 0$ since $x \neq y$ and is therefore a value 
    for which the condition must hold. Namely, 
    $$ 
        |x_n - x| < \varepsilon \text{ and } |x_n - y| < \varepsilon
    $$ 
    leading to
    $$ 
        |x - x_n| + |x_n - y| < 2\varepsilon = |x - y|
    $$ 
    which, via triangle inequality, yields 
    $$ 
        |x-y| = |x - x_n + x_n - y| \leq |x - x_n| + |x_n - y| < |x-y| 
    $$ 
    in particular 
    $$ 
        |x-y| < |x-y|
    $$ 
    which is not possible, a contradiction. 

\end{proof}

\newpage 
\begin{thm}[Algebra of Limits]
    \label{thm:algebra_limits}
    If $x_n \to x$ and $y_n \to y$, then: 
    \begin{enumerate}
        \item $x_n + y_n \to x + y$ 
        \item $x_ny_n \to xy$
        \item If $y_n \neq 0$ and $y \neq 0$, then $\frac{x_n}{y_n}
            \to \frac{x}{y}$.
    \end{enumerate}
\end{thm}
\begin{proof}[Proof of (1): Sum of Limits]
    Let $(x_n)$ and $(y_n)$ be convergent sequences with 
    $x_n \to x$ and $y_n \to y$. 

    Let $\varepsilon > 0$. Since both sequences converge to their 
    respective limits we have some 
    $N_1, N_2 \in \mathbb N$ such that 
    \begin{align*}
        |x_n - x| &< \varepsilon/2, \: \forall n \geq N_1 \\ 
        |y_n - y| &< \varepsilon/2, \: \forall n \geq N_2
    \end{align*}

    Let $N = \max\{N_1, N_2\}$, then $n \geq N$ satisfies 
    $n \geq N_1$ and $N \geq N_2$ so 
    $$ 
        |x_n - x| + |y_n - y| < \varepsilon
    $$ 

    Notice that via the triangle inequality we get 
    $$ 
        |(x_n + y_n) - (x + y)| = |(x_n - x) + (y_n - y)| 
        \leq |x_n - x| + |y_n - y| < \varepsilon
    $$ 
    completing the proof. 
\end{proof}

\begin{thm}
    A sequence $x_n$ converges to $x$ if and only if 
    $$
        \lim \sup x_n = \lim \inf x_n = x
    $$ 
\end{thm}
We will take this theorem without proof as it requires some background
about monotone sequences and completeness which are covered 
later. 

\begin{defn}[Limit of a function]
    \label{defn:limit_function}
    Let $f: D \subset \mathbb R \to \mathbb R$, and let 
    $a$ be a limit point of $D$. 

    We say 
    $$ 
        \lim_{x \to a} f(x) = L 
    $$ 
    if for every $\varepsilon > 0$ there exists $\delta > 0$ 
    such that 
    $$ 
        0 < |x - a| < \delta \Rightarrow |f(x) - L| < \varepsilon
    $$ 
\end{defn}

Later, when we get to metric spaces again, this condition becomes 
$$ 
    d_X(x,a) < \delta \Rightarrow d_Y(f(x), f(a)) < \varepsilon
$$ 
for continuity. 

\begin{thm}[Sequential criterion]
    $$ 
        \lim_{x\to a}f(x) = L \Leftrightarrow 
        \text{for every sequence } x_n \to a \text{ with }
        x_n \neq a, f(x_n) \to L
    $$ 
\end{thm}
\begin{proof}[Proof sketch]
    We only prove $\Rightarrow$, for now. 

    Assume $\lim_{x\to a}f(x) = L$. 

    Let $x_n \to a$ with $x_n \neq a$. 

    Given $\varepsilon > 0$, choose $\delta > 0$ from the 
    definition of the limit. 

    Since $x_n \to a$ there exists $N \in \mathbb N$ such that 
    with $n \geq N$ we have 
    $$ 
        |x_n - a| < \delta 
    $$ 

    Hence for $n \geq N$, 
    $$ 
        |f(x_n) - L| < \varepsilon
    $$ 

    Thus $f(x_n) \to L$.
\end{proof}

\newpage 
\section{Completeness}
\begin{defn}[Upper Bound]
    \label{defn:upper_bound}
    A set $A \subset \mathbb R$ is bounded above if 
    there exists $M \in \mathbb R$ such that 
    $$ 
        a \leq M, \: \forall a \in A
    $$ 

    Such an $M$ is called an upper bound. 
\end{defn}

\begin{defn}[Supremum]
    \label{defn:sup}
    Let $A \subset \mathbb R$. 

    A number $s \in \mathbb R$ is the supremum of $A$ if it 
    is an upper bound of $A$ and for any 
    upper bound $u$ of $A$ we have 
    $$ 
        s \leq u
    $$  
    and we use the notation 
    $$ 
        s = \sup A
    $$ 
\end{defn}

The completeness axiom says that every nonempty subset of 
$\mathbb R$ that is bounded above has a supremum in $\mathbb R$, 
this being the distinguishing quality separating 
$\mathbb R$ from $\mathbb Q$. 

Sidenote: You can also characterize the reals 
as the \emph{unique} ordered field containing $\mathbb Q$ which 
has the least upper bound property. More precisely, every 
$\mathbb F$ with this property satisfies $\mathbb F \cong \mathbb R$.

\begin{prop}
    If $A$ has a supremum then for every $\varepsilon > 0$, 
    there exists $a \in A$ such that 
    $$ 
        s - \varepsilon < a \leq s
    $$ 
\end{prop}
\begin{proof}
    Let $\varepsilon > 0$. If no $a \in A$ existed with the 
    desired property, then $s - \varepsilon$ would be a supremum, 
    contradicting minimality of $s$.
\end{proof}
This proposition becomes useful later in many arguments. 

The infimum $\inf A$ is also something we need and classically we 
define it as being the greatest lower bound, but for 
the purposes of keeping things simple, we 
just let the infimum of a set $A$, $\inf A$, be defined as 
$$ 
    \inf A = -\sup(-A)
$$ 

\newpage 
\begin{thm}[Monotone convergence]
    Let $(x_n)$ be a monotone increasing sequence 
    (a sequence with which $x_n \leq x_{n+1}$ for every 
    $n \in \mathbb N$) which is bounded above. 

    Then $(x_n)$ converges, and 
    $$ 
        \lim x_n = \sup\{x_n : n \in \mathbb N\}
    $$ 
\end{thm}
\begin{proof}
    Let 
    $$ 
        A = \{x_n : n \in \mathbb N\}
    $$ 
    
    Since $A$ is bounded above, $A$ has some supremum $s$. 
    We claim $x_n \to s$. 

    Let $\varepsilon > 0$. 

    By the supremum property, there exists $N$ such that 
    $$ 
        s - \varepsilon < x_N < \leq s
    $$ 
    
    Since the sequence is increasing, for all $n \geq N$, 
    $$ 
        s - \varepsilon < x_n \leq s
    $$ 

    Thus 
    $$ 
        |x_n - s| < \varepsilon
    $$ 
\end{proof}

\begin{lem}
    Every cauchy sequence in $\mathbb R$ is bounded. 
\end{lem}
\begin{proof}
    Let $(x_n)$ be cauchy. 

    Choose $\varepsilon = 1$. Then there exists $N$ such 
    that 
    $$ 
        |x_n - x_m| < 1, \: \forall n,m \geq N
    $$ 

    Fix $m = N$. Then for all $n \geq N$: 
    $$ 
        |x_n| \leq |x_N| + |x_n - x_N| < |x_N| + 1
    $$ 
    
    Thus all terms are bounded. 
\end{proof}

\begin{thm}
    Every cauchy sequence in $\mathbb R$ converges. 
\end{thm}
\begin{proof}[Proof idea]
    Let $(x_n)$ be cauchy. 

    $(x_n)$ is bounded. Use the cauchy property to construct nested 
    intervals. Show the intersection of these to be nonempty 
    via completeness of $\mathbb R$. 
    $(x_n)$ will converge to a point in this intersection. 

    A bit more formally, we choose indices $n_1, n_2, \ldots$ 
    such that 
    $$ 
        |x_n - x_m| < 2^{-k}, \: \forall n,m \geq n_k
    $$ 
    and define the intervals 
    $$ 
        I_k = [x_{n_k} - 2^{-k}, x_{n_k} + 2^{-k}]
    $$ 

    Then each $I_k$ is closed and bounded with $I_{k+1} \subset I_k$.
    Completeness wil give us 
    $$ 
        \bigcap_{k \in \mathbb N} I_k \neq \emptyset
    $$ 
    
    There will be an $x$ in this set which is the limit point. 
\end{proof}

\newpage 
\section{Open and Closed Sets in Metric Spaces}
Let $X$ be a set and $A \subseteq X$. 
Intuitively, a point $x$ is either \textbf{inside of} $A$, 
\textbf{outside of} $A$, or \textbf{on the boundary} of A.  
We know what it means to not be in $A$; $a \not\in A \Leftrightarrow 
a \in A^c$. 
We also know what $a \in A$ means, but set-theoretically we don't 
have a notion of being on the "boundary" of $A$. 
We can make sense of this notion in a metric space. 

Recall that the open ball is the set 
$B(x;r) = \{z \in X : d(x,z) < r\}$. Likewise we can define 
the closed ball as follows. 

\begin{defn}[Closed Ball]
    The closed ball centered at $x \in X$ with radius $r \geq 0$ in 
    $B(x;r) = \{z \in X : d(x,z) \leq r\}$. 
\end{defn}

Let $(X,d)$ be a metric space with $A \subseteq X$. 

\begin{itemize}
    \item $x \in X$ is an interior point of $A$ if 
        $B(x;r) \subseteq A$ for some $r > 0$. 
    \item $y \in X$ is an interior point of $A$ if 
        $B(x;r) \subseteq A^c$ for some $r > 0$. 
    \item $z \in X$ is a boundary point of $A$ if it is neither of 
        the above, i.e. 
        $B(z;r) \cap A \neq \emptyset$ and $B(z;r) \cap A^c \neq  
        \emptyset$ for every $r > 0$.
\end{itemize}

Notably, every point in $X$ is one of these three. 

\begin{itemize}
    \item $A^0 = \{\text{all interior points of } A\}$
    \item $\partial A = \{\text{all boundary points of } A\}$ 
    \item $\overline A = A \cup \partial A = ((A^c)^0)^c$
\end{itemize}

\begin{prop}
    For any $A \subset X$, we have $\partial A = \partial (A^c)$.
\end{prop}

\begin{thm}
    Useful characterizations of openness: 

    $A \subseteq X$ is open if $A = A^0$

    $A \subseteq X$ is open if $A$ contains none of its boundary 
    points. 

    $A \subseteq X$ is open if $A \cap \partial A = \emptyset$

    $A \subseteq X$ is open if $\forall x \in A$ there is some 
    $r > 0$ s.t. $B(x;r) \subseteq A$ 
\end{thm}

\begin{thm}
    Useful characterizations of openness: 

    $B \subseteq X$ is closed if $B = \overline B$

    $B \subseteq X$ is closed if $A$ contains all of its boundary 
    points. 

    $A \subseteq X$ is closed if $ \partial B\subseteq B$
\end{thm}

\newpage 
\begin{prob}
    Consider $X = \mathbb R$ with the canonical metric $|\cdot|$. 
    Show that $(a,b)$ is open and $[a,b]$ is open for 
    $a \leq b \in \mathbb R$, and $(a,b]$ is 
    neither open nor closed for $a < b$.
\end{prob}
\begin{proof}
    Let $x \in (a,b)$, i.e. $a < x < b$. Take 
    \[
        r := \min\{x - a, x - b \} > 0
    \]
    Take any $y \in (x-r, x+y)$. 
    Then 
    \[
        y > x - r \geq a, \: y < x + r \leq b
    \]
    Therefore 
    \[
        (x-r, x + r) \subset (a,b)
    \]

    In other words, every $x \in (a,b)$ admits and open ball 
    contained entirely in the interval, so $(a,b)$ is open.

    Notice that $\partial(a,b) = \{a,b\}$ and that 
    $[a,b] = \partial(a,b) \cup (a,b)$ hence $[a,b]$ is the closure 
    of $(a,b)$ and thus is closed.  

    It is clear that $(a,b]$ is neither open nor closed as 
    $\partial(a,b] = \{a,b\} \not \subseteq (a,b]$ and 
    $(a,b] \cap \partial(a,b] \neq \emptyset$. 
\end{proof}

\newpage 
\section{Week 4 problem set}
\begin{prop}[Proposition 3.1.4 in Spaces]
    \label{prop:reverse_triangle}
    If $(X,d)$ is a metric space with $x,y,z \in X$, then 
    \[
        |d(x,y) - d(y,z)| \leq d(x,z)
    \]
\end{prop}
\begin{prob}
    Prove \Cref{prop:reverse_triangle}. 
\end{prob}
\begin{proof}
    Let $(X,d)$ be a metric space and recall the standard 
    triangle inequality: 
    \[
        d(x,z) \leq d(x,y) + d(y,z)
    \]
    Now observe the following rearangements: 
    \begin{align*}
        d(x,y) &\leq d(y,z) + d(x,z) \\ 
        d(x,y) - d(y,z) &\leq d(x,z) \\ 
                        &\text{and} \\ 
        d(x,y) &\leq d(y,z) + d(x,z) \\ 
        d(y,z) &\leq d(x,y) + d(x,z) \\ 
        d(y,z) - d(x,z) &\leq d(x,y) \\ 
        -d(x,z) &\leq d(x,y) - d(y,z) 
    \end{align*}

    Together: 
    \[
        |d(x,y) - d(y,z)| \leq d(x,z)
    \]
\end{proof}
\begin{prob}[3.1.6 Spaces]
    Let $(V,||\cdot||)$ be a normed space. Show that 
    it induces a norm, i.e. 
    \[
        d(x,y) := ||x-y||
    \]
    is a norm.
\end{prob}
\begin{proof}
    Let $(V,||\cdot||)$ be a normed space. 

    \textbf{Non-negativity and Identity of Indiscernibles:}

    \[
        d(x,y) = ||x-y|| \geq 0 
    \]
    since $x-y \in V$ and $||\cdot||$ is non-negative. 
    
    \[
        d(x,x) = ||x-x|| = ||0|| = 0
    \]
    Assume $d(x,y) = 0$. 
    \[
        d(x,y) = ||x-y|| = 0
    \]
    Then $x-y = 0 \Rightarrow x = y$.

    \textbf{Symmetry:}

    Recall for a norm we have $||\alpha x|| = |\alpha| ||x||$, 
    hence 
    \[
        d(x,y) = |1|||x-y|| = ||-1(x-y)|| = ||y-x|| = d(y,x)
    \]

    \textbf{Triangle Inequality:}
    \begin{align*}
        d(x,z) &= ||x-z|| = ||x - (y + y) - z|| \\ 
               &\leq ||x-y|| + ||y - z|| \\ 
               &= ||x-y|| + ||z-y|| \\ 
               &= d(x,y) + d(y,z)
    \end{align*}
\end{proof}

\begin{prob}[3.1.7 Spaces]
    Show that if $x_1, x_2, \ldots, x_n$ are points in a metric space,
    then 
    \[
        d(x_1,x_n) \leq \displaystyle\sum_{i=1}^{n-1} d(x_i, x_{i+1})
    \]
\end{prob}
\begin{proof}
    We proceed by induction on $n \in \mathbb N$. 

    \textbf{Base Case ($n=1$).}

    Clearly, 
    \[
        d(x_1, x_1) \leq d(x_1, x_1)
    \]

    \textbf{Hypothesis.}
    Now assume, for any $k \in \mathbb N$, 
    \[
        d(x_1, x_k) \leq \displaystyle\sum_{i=1}^{k-1}d(x_i, x_{i+1})
    \]

    \textbf{Induction.}
    Let $n = k+1$. 

    \begin{align*}
        d(x_1, x_n) = d(x_1, x_{k+1}) &\leq d(x_1, x_k) + 
        d(x_k, x_{k+1}) \\ 
    &\leq \left(\displaystyle\sum_{i=1}^{k-1} d(x_i, x_{i+1})\right) 
    + d(x_k, x_{k+1}) \\ 
    &= \displaystyle\sum_{i=1}^{n-1} d(x_i, x_{i+1})
    \end{align*}
    as desired. 
\end{proof}

\begin{prob}[3.2.1 Spaces]
    Assume that $(X,d)$ is a discrete metric space. Show that 
    the sequence $\{x_n\}$ converges to $a$ if and only if there is an 
    $N \in \mathbb N$ such that $x_n = a$ for all $n \geq N$. 
\end{prob}
\begin{proof}
    Let $(X,d)$ be a discrete metric space, i.e. a metric space where
    \[
        d(x,y) = 
        \begin{cases}
            0 & \text{if } x = y \\ 
            1 & \text{otherwise}
        \end{cases}
    \]

    \textbf{$\Leftarrow$.} 
    
    Assume there is some $N \in \mathbb N$ such that 
    $\forall n \geq N$, 
    \[
        x_n = a
    \]
    Then it is clear that for any $\varepsilon > 0$, 
    \[
        x_n = 0 \Rightarrow  d(x_n,a) = 0 < \varepsilon
    \]
    so $\{x_n\} \to a$. 

    \textbf{$\Rightarrow$.}

    Assume that $\{x_n\} \to a$. Then for any $\varepsilon > 0$ 
    there exists $N \in \mathbb N$ such that for $n \geq N$, then 
    \[
        d(x_n, a) < \varepsilon
    \]
    In particular, this must hold for $\varepsilon = 0.5$. 
    Notice that this requires $x_n = a$ since otherwise we would 
    have $1 < 0.5$, a contradiction. 
\end{proof}

\begin{prob}[3.2.5 Spaces]
    Let $(X,d)$ be a metric space and fix some $a \in X$. 
    Show that the function $f:X \to \mathbb R$ defined as 
    \[
        f(x) = d(x,a)
    \]
    is continuous. 
    Note: $\mathbb R$ is finite dimensional so we are free 
    to choose any metric. $d{\mathbb R}(x,y) = |x-y|$ is fine.
\end{prob}
\begin{proof}
    Let $(X,d)$ be a metric space and fix $a \in X$. 
    Let $f$ be defined as above. 

    Consider a family of sequences in $X$ such that every sequence 
    $\{x_n\}$ converges to $a \in X$. Let $\{x_n\}$ be some arbitrary
    sequence in this family.

    Then, $\forall \varepsilon > 0$ we have some natural number 
    $\mathbb N$, s.t. for any $n \geq N$,
    \[
        d(x_n, a) < \varepsilon
    \]

    Notice that 
    \[
        d(x_n,a) = |d(x_n,a) - 0| < \varepsilon
    \]
    where $\varepsilon > 0$ was arbitrary. Hence 
    $f(\{x_n\})$ converges to $0 = d(a,a) = f(a)$. 

    Thus $f$ is continuous.
\end{proof}
\begin{prob}
    Let $(X,d)$ be a metric space. Prove that every finite 
    subset of $X$ is closed. 
\end{prob}
\begin{proof}
    Recall that proposition $3.3.13$ from Spaces tells us that 
    for any finite collection $F_1, \ldots, F_n$ of closed sets, 
    their union 
    \[
        \bigcup_{i \in [n]} F_i
    \]
    is closed. 

    Consider any singleton $\{x\} \subseteq X$. It is clear that 
    $\{x\}$ is closed since $\{x\}^c$ is open. Observe that 
    the open ball $B(y;\varepsilon) \subseteq \{x\}^c$ for any 
    $y \in X \setminus \{x\}$ with $\varepsilon = d(x,y)$.
    
    Let $\{x_1,\ldots,x_n\} \subseteq X$ be any finite subset. As 
    shown above, $\{x_i\}$ is closed, and by proposition 3.3.13 
    \[
        \{x_1,\ldots,x_n\} = \bigcup_{i\in[n]} \{x_i\}
    \] 
    is closed. 
\end{proof}

\begin{prob}[3.3.13 Spaces]
    A metric space $(X,d)$ is disconnected if it is the union 
    of two non-empty, disjoint and open subsets. If it is not 
    disconnected it is connected. 
    
    a) Let $X = (-1,1) \setminus \{0\}$ and let $d$ be the usual 
    metric on $X$. Show that $(X,d)$ is disconnected. 

    b) Let $X = \mathbb Q$ and let $d$ be the usual metric again. 
    Show that $(X,d)$ is disconnected. 

    c) Assume that $(X,d)$ is a connected metric space
    and that $f: X \to Y$ is continuous and surjective. Show that 
    $Y$ is connected.
\end{prob}
\begin{proof}[Proof of (a)]
    It is clear that $(-1,0)$ and $(0,1)$ are open with respect to 
    $d(x,y) = |x-y|$ as, we can find an open ball around any 
    point in either. Since 
    \[
        X = (-1,0) \cup (0,1)
    \]
    we conclude that $X$ is disconnected. 
\end{proof}
\begin{proof}[Proof of (b)]
    Recall that $\sqrt 2 \not\in \mathbb Q$ so 
    the open subsets 
    \[
        (-\infty, \sqrt 2) \cap \mathbb Q 
        \text{ and }
        (\sqrt 2, \infty) \cap \mathbb Q 
    \]
    Both of these sets are open in $\mathbb R$ and thus they 
    are also open in $\mathbb Q$.
\end{proof}
\begin{proof}[Proof of (c)]
    Suppose, for a contradiction that we have some 
    continuous surjection $f : X \to Y$ where $X$ is connected 
    and $Y$ is not. 

    From surjection we can gleam that for any $y \in Y$ there 
    is some $x \in X$ such that $f(x) = y$. From continuity
    at every point we have that there is some 
    $\delta > 0$ for any $\varepsilon > 0$ such that
    \[
        f\left[B_X(x;\delta)\right] \subseteq B_Y(f(x);\varepsilon)
    \]
    By assumption 
    \[
        Y = O_1 \cup O_2
    \]
    for some nonempty, disjoint, open $O_1$ and $O_2$.  
    So for any point in $O_1$ or $O_2$ we have an open neighbourhood 
    surrounding it. Consider some family open sets in 
    $O_1$, $\{\omega_n\}_{n\in\mathbb N}$ such that 
    \[
        \bigcup_{n\in\mathbb N} \omega_n = O_1
    \]
    It is clear that $\omega_i \not \in O_2$ for any $\omega_i$. 
    Suppose $\omega_i$ is centered around $y_i \in Y$. By surjectivity
    we have that there are some $x_i \in X$ such that 
    the image open ball around $x_i$ goes to the open ball around 
    $y_i$. It is not hard to see that we are characterizing 
    an open set in $X$ which is mapped to $O_1$. Repeat this process 
    for $O_2$ and we will see that since there is no open ball 
    which falls in both sets, and correspondingly via 
    continuity there then is no ball in $X$ which falls in the 
    pre-images of both $O_1$ and $O_2$, hence we have partitioned 
    $X$ into two disjoint non-empty subsets. So $X$ is disconnected, 
    a catastrophic contradiction.
\end{proof}
\begin{proof}[Another attempt at a proof of (c)]
    Suppose, for a contradiction that we have a 
    continuous surjection $f: X \to Y$ where $X$ is connected and 
    $Y$ is not. 

    Let $A \subseteq X$ be a subset such that $f\mid_A : A \to Y$ 
    is a bijection. Since it is the restriction of $f$ to $A$ is 
    still continuous $f$ constitutes a homeomorphism from $A \to Y$.
    Then, the inverse $g : Y \to A$ exists, which is still continuous 
    of course. 

    Recall that a function $g$ from a metric space $Y \to A$ is 
    continuous if and only if for any $\varepsilon > 0$ we 
    have some $\delta > 0$ such that 
    \[
        g\left[B_Y(y;\delta)\right] \subseteq B_A(g(y);\varepsilon)
    \]
    for any $y \in Y$.
    By assumption, there exist $O_1$ and $O_2$ such that 
    \[
        Y = O_1 \cup O_2
    \]
    with $O_1, O_2 \neq \emptyset$ and disjoint. 
    Furthermore, $O_1$ and $O_2$ are open. 
    We now claim that $A$ is partitioned into 
    two disjoint, nonempty, open sets
    \[
        g[O_1] \text{ and } g[O_2]
    \]
    It is not hard to see that they are both open as the 
    open ball around any point in $O_1$ or $O_2$ is sent to 
    some open ball around a point in their image via continuity. 
    Furthermore it is clear that they are nonempty since 
    $g$ is a bijection and $O_1, O_2$ are nonempty. 

    Lastly, assume (for contradiction) 
    that there is some $y \in Y$ such that 
    $g(y) \in g[O_1]$ and $g(y) \in g[O_2]$, i.e. 
    they are not disjoint. 
    Then we would have $f\mid_A(g(y)) \in O_1$ and 
    $f\mid_A(g(y)) \in O_2$. Recalling that $f\mid_A \circ g = id_Y$ 
    we have that $y \in O_1$ and $y \in O_2$, but it is established 
    that no such point exists, contradicting the 
    assumption that $g[O_1] \cap g[O_2] \neq \emptyset$.

    Thus we have shown that $A$ is disconnected, but then 
    $X$ is also disconnected, a catastrophic contradiction to 
    our original assumption.
\end{proof}

\begin{prob}[3.3.13 Spaces (again)]
    A space $X$ is path connected if there is a 
    continuous $r : [0,1] \to X$ for every pair $x,y \in X$
    such that $r(0) = x$ and $r(1) = y$.

    d) Let $d$ be the usual metric on $\mathbb R^n$: 
    \[
        d(x,y) = ||x-y|| = \sqrt{\displaystyle\sum_{i=1}^{n} 
        (x_i - y_i)^2}
    \]
    Show that $(\mathbb R^n, d)$ is path-connected. 

    e) Show that every path-connected metric space is connected.
\end{prob}
\begin{proof}[Proof of (d)]
    Consider two distinct points $x,y \in \mathbb R^n$. Then 
    \[
        x = (x_1,\ldots,x_n), \ y = (y_1,\ldots,y_n)
    \]
    Consider the vector 
    \[
        (y - x) \cdot z = (y_1 - x_1, \ldots, y_n - x_n) \cdot z, \; 
        z \in [0,1]
    \]
    It is clear that 
    \[
        x + (y-x) \cdot 0 = x \text{ and } x + (y - x) \cdot 1 = y  
    \]
    So define $r: [0,1] \to X$ by 
    \[
        r(z) := x + (y-x) \cdot z
    \]
    Let $z \in [0,1]$ and fix any $z_0 \in \mathbb Z$, 
    let $\varepsilon > 0$ and choose $\delta := 
    \frac{\varepsilon}{||x-y||}> 0$. 
    Assume
    \[
        |z - z_0| < \delta 
    \]
    Then, 
    \begin{align*}
        ||r(z) - r(z_0)|| 
        &= ||(x + (y-x) \cdot z) - (x + (y-x) \cdot z_0)|| \\ 
        &= \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            (x_i - zx_i + zy_i) 
            - 
            (x_i - z_0x_i + z_0y_i)
        \right)^2
        \right)^{1/2} \\ 
        &= \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            (z_0-z)x_i + (z - z_0)y_i
        \right)^2
        \right)^{1/2} \\ 
        &= \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            (z - z_0)(y_i - x_i)
        \right)^2
        \right)^{1/2} \\ 
        &= |z - z_0| \left(\displaystyle\sum_{i=1}^{n} 
        \left(
            y_i - x_i
        \right)^2
        \right)^{1/2} \\ 
        &= |z-z_0| \cdot ||x - y||
        < \delta \cdot ||x-y|| = \frac{\varepsilon}{||x-y||}||x-y|| 
        \\ 
        &= \varepsilon
    \end{align*}
\end{proof}

\newpage 
\section{Week 6 problem set}
\begin{prob}[Problem relating to Section 3.3]
    Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces, let $f:X\to Y$ be a continuous function, let $y\in Y$ be some given point, and consider the problem of finding an $x\in X$ such that $f(x)=y$ (that is, we wish to solve the above equation). Prove that the set of solutions of this equation is a closed subset of $X$.  

    \emph{Hint:} Phrase the question in terms of finding $f^{-1}$ of a closed set.
\end{prob}
\begin{proof}
    Apply the assumptions of the problem description.

    Let $S_y \subseteq X$ denote the set of solutions to 
    $f(x) = y \in Y$.
    Notice that $S_y$ is the set $f^{-1}[\{y\}]$. Since $\{y\}$ is 
    a singleton it is a closed set. 
    In the topological sense, if $f$ is continuous then the preimage 
    of every closed set in $Y$ is closed in $X$. 
    This would complete the proof, but let us give an analytical 
    way of doing it instead. 

    Once again let $S_y \subset X$ denote the set of $x \in X$ such 
    that $f(x) = y \in Y$. Let $\{x_n\}$ be some sequence in 
    $S_y$ such that $x_n \to x$ in $X$. Now we need to show 
    that $x \in S_n$, i.e. $f(x) = y$. Since $x_n \in S_y$ 
    we have that (for every $n \in \mathbb N$) 
    \[
        f(x_n) = y
    \]
    $f$ is continuous so via sequential continuity we get 
    \[
        f(x_n) = f(x)
    \]
    i.e. 
    \[
        f(x) = y
    \]
    Thus $x \in S_y$. 
    Since $\{x_n\}$ was an arbitrarily chosen convergent sequence 
    in $S_y$ and we found that $x_n \to x \in S_y$ we conclude 
    that $S_y$ contains all it's limit points. In other 
    words $S_y$ is closed. 
\end{proof}
\begin{prob}
    Prove that $(\mathbb{Z},d)$, where $d(x,y)=|x-y|$, is complete.  
    \emph{Hint:} What does it mean for a sequence in $(\mathbb{Z},d)$ to converge or to be Cauchy?
\end{prob}
\begin{proof}
    Let $\{x_n\}$ be a cauchy sequence in $\mathbb Z$. 
    Then, for every $\varepsilon > 0$ there is some $N \in \mathbb N$
    s.t. 
    \[
        |x_n - x_m| < \varepsilon
    \] 
    for every $n,m \geq N$. 
    Notice that we then require $x_n = x_m$ for all $n,m \geq N$ 
    since if that weren't the case we would have 
    $0 < \varepsilon := 0.5 < 1 \leq |x_n - x_m|$. Thus 
    every cauchy sequence in $\mathbb Z$ will necessarily settle 
    at some $x \in \mathbb Z$ and be constant. In other words, 
    $\{x_n\} \to x \in \mathbb Z$, as desired.  
\end{proof}
\begin{prob}[Problem 3.3.3 Spaces]
    Assume that $F$ is a nonempty, closed and bounded 
    subset of $\mathbb R$ with the usual metric. Show that 
    $\inf F \in F$ and $\sup F\in F$. Give an example of a 
    bounded, but not closed set such that it contains it's supremum
    and infinmum.
\end{prob}
\begin{proof}
    Suppose $\emptyset \neq F \subseteq \mathbb R$ with 
    $F$ closed and bounded. 

    Recall that since $F$ is bounded there is some finite 
    $r > 0$, $x \in F$ such that 
    \[
        F \subseteq (x-r,x+r)
    \]
    Recall that for any nonempty subset of $\mathbb R$ there 
    exists a least upper bound and greates lower bound, i.e.
    $\inf F \in \mathbb R$ and $\sup F \in \mathbb R$. 

    Let $\{x_n\}$ be a sequence in $F$ such that $\{x_n\} \to \sup F$.
    By closedness $\sup F \in F$. Apply this same reasoning to 
    the infimum to get the desired result. Notice that we required 
    boundedness as, if $F$ wasn't bounded above and below we 
    might have had $\inf F = -\infty$ or $\sup F = \infty$. In 
    that case we couldn't have constructed sequences converging 
    to these points.

    Let $F = [0,1] \setminus \{\frac{1}{2}\}$. Clearly not closed 
    since any sequence converging to $1/2$ contradicts it being 
    closed. It is bounded above and below and $\inf F = 0 \in F$ 
    and $\sup F = 1 \in F$. 
\end{proof}
\begin{prob}[Problem 3.3.11 Spaces]
    Prove Proposition 3.3.12. Find an infinite collection of open 
    sets whose intersection is closed. 
\end{prob}
\begin{prop}[Proposition 3.3.12 from Spaces]
    Let $(X,d)$ be a metric space. 

    a) If $\mathcal G$ is a finite or infinite collection of 
    open sets, then 
    \[
        \bigcup_{G \in \mathcal G}G 
    \]
    is open.

    b) If $G_1, \ldots, G_n$ is a finite collection of open sets 
    then 
    \[
        \bigcap_{i=1}^n G_i
    \]
    is open.
\end{prop}
\begin{proof}[Proof of (a)]
    Consider a (potentially infinite) family 
    $\mathcal G = \{G_1,G_2,\ldots\}$ of open sets. 
    Define 
    \[
        \Gamma := \bigcup_{G \in \mathcal G} G
    \]
    Take any arbitrary $x \in \Gamma$. Then there is some 
    $G_i$ such that $x \in G_i$. 
    As $G_i$ is open there is some $r\in \mathbb R^+$ with 
    \[
        B(x;r) \subseteq G_i \subseteq \Gamma
    \]
    Hence $\Gamma$ is open. 
\end{proof}
\begin{proof}[Proof of (b)]
    Let $\mathcal G = \{G_i\}_{i \in [n]}$ be a finite family of 
    open sets.  
    Define 
    \[
        \Gamma := \bigcap_{i\in[n]} G_i
    \]
    Suppose $x \in \Gamma$. Then $\bigwedge_{i=1}^n x \in G_i$ and 
    for each $G_i$ there is some $r_i > 0$ such that 
    \[
        B(x;r_i) \subseteq G_i
    \]
    Then 
    \[
        B(x;\min\{r_i : 1 \leq i \leq n\}) = 
        \bigcap_{i=1}^n B(x;r_i) \subseteq \bigcap_{i \in [n]} G_i 
        = \Gamma
    \]
    so $\Gamma$ is open.
\end{proof}
\begin{ex}[Counter example for infinite intersection.]
    Consider the metric space $(\mathbb R, |\cdot|)$. 
    Consider the following infinite family of open sets 
    \[
        \left\{ 
            (-1/n,1/n)
        \right\}_{n \in \mathbb N}
    \]      
    Clearly, 
    \[
        \bigcap_{n\in\mathbb N} (-1/n,1/n) = \{0\}
    \]
    which is closed in $\mathbb R$.
\end{ex}
\begin{prob}
    prob
    Consider $X=\mathbb{R}$ with the canonical metric $d(x,y)=|x-y|$. The \emph{support} of a function $f:\mathbb{R}\to\mathbb{R}$ is the set of points $x$ where $f(x)\neq 0$. Prove that the support of a continuous function is always open.  
    \emph{Note:} In the literature, the "support" of $f$ is usually defined to be the closure of the above set, which is of course closed, not open.
\end{prob}
\begin{proof}
    Let $f:\mathbb R\to\mathbb R$ be continuous and let
    \[
        \Omega := \{x\in\mathbb R : f(x)\neq 0\}.
    \]
    Suppose, for a contradiction, that $\Omega$ is not open. 
    Then there exists
    $x\in\Omega$ such that for every $r>0$ there is some 
    $y\in(x-r,x+r)$ with
    $f(y)=0$.

    Since $f$ is continuous at $x$, for $\varepsilon := |f(x)| > 0$ 
    there exists
    $\delta>0$ such that
    \[
        |f(y)-f(x)|<\varepsilon \quad \text{whenever } |y-x|<\delta.
    \]
    By assumption, there exists $y\in(x-\delta,x+\delta)$ 
    with $f(y)=0$.
    Then
    \[
        |f(x)| = |f(x)-f(y)| < |f(x)|,
    \]
    a contradiction. Hence $\Omega$ is open.
\end{proof}
\begin{prob}
    Show that the equation $\cos t = 2t$ has a unique solution.  
    \emph{Hint:} Formulate the problem as finding the fixed point of a function $f$.
\end{prob}
\begin{proof}
    Banach's fixed-point theorem tells us that for some complete 
    metric space $X$, a contraction $F:X\to X$ will have a unique 
    $t \in X$ such that 
    \[
        t = F(t)
    \]
    Let $F: \mathbb [0,\pi/2] \to \mathbb [0,\pi/2]$ be defined by 
    \[
        F(t) := \frac{1}{2}\cos t
    \]
    Clearly, $F(t) = t$ if and only if $\cos t = 2t$. 
    Furthermore, as a closed bounded subset of a compelte emtric  
    space,  $([0,\pi/2], |\cdot|_{[0,\pi/2]})$ is complete.  
    Now all we need is to show that 
    $F$ constitutes a contraction on $\mathbb R$. 
    Notice that 
    \[
        \frac{1}{2}\cos(t) \in [0,1/2], \: t \in [0,\pi/2]
    \]
    so $F$ ceirtanly constitutes a contraction. Thus 
    by Banach's fixed point theorem there is a unique 
    point $t \in [0,\pi/2]$ such that $t = F(t)$. $t$ constitutes 
    the unique solution to 
    \[
        \cos(t) = 2t
    \]
\end{proof}

\newpage 
\section{3.4 \& 3.5}
\begin{prop}
    Let $(X,d)$ be a metric space. Let $f : X \to X$ be 
    a contraction. Then $f$ is continuous.
\end{prop}
\begin{proof}
    Let $f : X \to X$ be a contraction. In other words, for 
    some $\omega \in (0,1)$, let 
    $f$ satisfy  
    \[
        d(f(x), f(y)) \leq \omega d(x,y), \: \forall x,y \in X
    \]
    Let $\varepsilon > 0$. 
    Define $\delta = \frac{\varepsilon}{\omega}$.
    Suppose $d(x,y) < \delta$. Then 
    \[
        d(f(x),f(y)) \leq \omega d(x,y) < \omega \cdot \delta 
        = \varepsilon
    \]
\end{proof}

Recall that completeness is a very usefull property as if a 
sequence seems to converge then it does converge, and to a 
point in the space. However, sometimes it is hard to 
show that a sequence is cauchy. 
It would be nice to substitute this requirement to get 
some other way of showing convergence of sequence in a space. 
We could require that every sequence converges, but that 
is a ridiculously strict requirement and false most of the time. 
So instead, we require all sequences to have convergent subseqneces. 

Recall the definition of a subsequence: 
\begin{defn}[Subsequence]
    Let $\{x_n\}_{n\in \mathbb N}$ be a sequence. A subsequence is 
    a sequence of the form $\{x_{n(k)}\}_{k\in\mathbb N}$, 
    where $n(k) \in \mathbb N$ and 
    \[
        n(1) < n(2) < n(3) < \cdots
    \]
\end{defn}
Useful note: $n(k) \geq k$.
\begin{prop}
    Let $(X,d)$ be a metric space. If $\{x_n\}_n$ converges, then 
    all possible subsequences converge, and the limit is the 
    same. 
\end{prop}
\begin{proof}
    Let $\varepsilon > 0$, let $N \in \mathbb N$ be such that 
    $d(x_n, x) < \varepsilon$. Then $n(k) \geq n \geq N$
    so also 
    \[
        d(x_{n(k)}, x) < \varepsilon
    \]
\end{proof}
\begin{defn}[Compactness]
    A metric space $(X,d)$ is said to be \emph{compact} if every 
    sequence $\{x_n\}_n$ has a convergent subsequence 
    $\{x_n(k)\}_k$.
\end{defn}
\begin{defn}
    A subset $K \subseteq X$ of a metric space $(X,d)$ 
    is compact if $(K,d)$ is compact. 
\end{defn}
\begin{thm}
    Let $(X,d)$ be a metric space. If $K \subseteq X$ is finite 
    then $(K,d)$ is compact.
\end{thm}
\begin{proof}
    Let $\{x_n\}_{n\in\mathbb N}$ be a sequence in 
    $K = \{k_1, k_2, \ldots, k_m\}$. 
    As $\{x_n\}_n$ is infinite, there must be at least one 
    element $k_i$ where $x_j = k_i$ for infinitely many 
    $j \in \mathbb N$. 
    Then we can pick out indices such that 
    $\{x_n(p)\}_{p\in\mathbb N}$ is a constant sequence for 
    some $k_i \in K$ and thus convergent.
\end{proof}
\begin{thm}
    Let $(X,d)$ is compact. Then $(X,d)$ is complete. 
\end{thm}
\begin{proof}
    Let $\{x_n\}_n$ be cauchy. As $(X,d)$ is compact there exists 
    some convergent $\{x_{n(k)}\}_k$ which converges to $x \in X$.  
    For $\varepsilon > 0$, let $N_1 \in \mathbb N$ be s.t. 
    \[
        d(x_{n(k)}, x) < \varepsilon, \: n \geq N_1
    \]
    and let $N_2 \in \mathbb N$ s.t. 
    \[
        d(x_n, x_m) < \varepsilon, \: n,m \geq N_2
    \]
    Let $N = \max\{n(N_1),N_2\}$. If $m \geq N$ then 
    \[
        d(x_m, x) \leq \underset{<\varepsilon}{d(x_m, x_{n(m)})}  
        + \underset{<\varepsilon}{d(x_{n(m)}, x)} < 
        2\varepsilon
    \]
    Hence $\{x_n\}_n$ converges to $x \in X$.
\end{proof}
\begin{thm}
    If $K \subseteq X$ is compact then it is closed and bounded. 
\end{thm}
\begin{proof}
    Let $K \subseteq X$ be compact.

    \textbf{Closed.} 

    Let $\{x_n\}_n$ be a sequence in $K$ converging to $x \in X$. 
    By compactness we can find a subsequence $\{x_{n(k)}\}_k$ 
    converging to some $y \in K$. Then $x = y \in K$, as the 
    subsequence converges to the same value. 

    \textbf{Bounded.}

    Assume $K$ is not bounded. Fix $\overline x \in X$. Then 
    for every $n \in \mathbb N$, there is some $x_n \in K$ with 
    \[
        d(x_n, \overline x) \geq n
    \]
    Let $\{x_{n(k)}\}_k$ be a convergent subsequence of $\{x_n\}_n$.
    Then 
    \[
        n(k) \leq d(x_{n(k)}, \overline x) 
        \underset{k \to \infty}{\to} d(x,\overline x)
    \]
    In other words, a value which tends to infinity is less than 
    a fixed value. 
\end{proof}
\begin{prop}
    Let $X = \mathbb R^n$, $d(x,y) = ||x-y||$ 
    (all norms are equivalent in $\mathbb R^n$). 
    Let $K \subseteq \mathbb R^n$. Then 
    \[
        K \text{ is compact}
        \Leftrightarrow 
        K \text{ is closed and bounded}
    \]
\end{prop}
\begin{proof}
    The l2r direction is already covered so we tackle the other 
    way. 

    Let $K$ be closed and bounded. Let $\{x_n\}_n$ be a sequence 
    in $K$. 
    Then $\{x_n\}_n$ is bounded, so by Bolzano-Weierstrass, there 
    is a convergent subsequence $\{x_{n(k)}\}_k$ converging to 
    some $x \in \mathbb R^n$. Since $K$ is closed $x \in K$. 
    We conclude that $K$ is compact. 
\end{proof}
\begin{thm}
    Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces with 
    $f:X\to Y$ continuous. If $K \subseteq X$ is compact then 
    $f[K]$ is, also.
\end{thm}
\begin{thm}
    If $(X,d)$ is compact and $f : X \to \mathbb R$ continuous. 
    Then $f$ attains a minimum and maximum.
\end{thm}

\begin{defn}
    Let $(X,d)$ be a metric space. A set $K \subseteq X$ is 
    \emph{totally bounded} if $\forall \varepsilon > 0$, 
    there exists finitely many points $x_1,\ldots,x_n \in K$ 
    such that 
    \[
        K \subseteq \bigcup_{i=1}^n B(x_i;\varepsilon)
    \]
\end{defn}
In other words, we say $K$ is totally bounded if we can find 
finitely many open balls which cover it for any 
radius $\varepsilon$. This sounds a lot like the topological 
definition of compactness (Every open cover has a finite subcover).
What we have here is a stronger property than meere boundedness. 
\begin{lem}
    Every compact set is totally bounded.
\end{lem}
\begin{proof}
    Let $K \subseteq X$ be a compact subspace of a metric 
    space $(X,d)$, and assume it is not totally bounded.   
    So $K$ compact with 
    \[
        K \not\subseteq \bigcup_{i=1}^n B(x_i;\varepsilon)  
    \]
    for any choice of $x_1, \ldots,x_n$ for some $\varepsilon$.
    Pick any $x_1 \in K$. Then $K \not\subseteq B(x_1;\varepsilon)$,
    so there is some $x_2 \in K \setminus B(x_1;\varepsilon)$.
    Iteratively pick $x_1,\ldots,x_n$, pick any 
    $x_{n+1} \in K \setminus \bigcup_{i=1}^n B(x_i;\varepsilon)$. 
    Note: $d(x_n, x_m) \geq \varepsilon$ for any $x \neq m$. 
    Then $\{x_n\}_n$ is a sequence in $K$, so has convergent 
    subsequence with limit $x \in K$. But then 
    $\varepsilon \leq d(x_n,x) + d(x,x_m) 
    \underset{x,m \to \infty}{\to} 0$.
\end{proof}

\begin{defn}
    Let $(X,d)$ be a metric space. A set $B \subseteq X$ is 
    separable if there exists a dense, countable set 
    $D \subseteq B$.
\end{defn}
\begin{ex}
    \begin{itemize}
        \item $\mathbb R$ is separable ($\mathbb Q \subseteq 
            \mathbb R$)
        \item Any subset of $\mathbb R$ is separable 
        \item $B_1, B_2, \ldots$ separable, then 
            \[
                \bigcup_{i\in\mathbb N} B_i
            \]
            is, also 
        \item $\ell^p(\mathbb R)$ is separable for all 
            $p < \infty$, but not $p = \infty$
    \end{itemize}
\end{ex}
\begin{thm}
    Let $(X,d)$ be a complete metric space, $K \subseteq X$. 
    \[
        K \ \text{compact} \Leftrightarrow K \ \text{totally bounded}
    \]
\end{thm}
\begin{thm}
    Every compact set is separable.
\end{thm}
\newpage 
\section{3.6 - Compactness IV}
\begin{defn}
    Let $(X,d)$ be a metric space and let $K \subseteq X$. 
    An \emph{open covering} of $K$ is a family of open sets 
    $\mathcal F$ satisfying 
    \[
        K \subseteq \bigcup_{\mathcal O \in \mathcal F} \mathcal O
    \]
\end{defn}
\begin{defn}
    A set $K \subseteq X$ has the open covering property if 
    for any open covering $\mathcal F$ of $K$, 
    there exists $\mathcal O_1,\ldots,\mathcal O_n \in \mathcal F$
    such that $\{\mathcal O_1,\ldots, \mathcal O_n\}$ is an 
    open covering of $K$.
\end{defn}
\begin{thm}
    A set $K \subseteq X$ is compact if and only if it has 
    the open covering property. 
\end{thm}
This is a very powerful classification of compactness and is the 
one you typically first encounter in a topology course. 
Notice that we don't need to assume completeness of $X$, 
closedness of $K$ (as that comes for free), etc. 

\newpage 
\section{4.1 - Models of Continuity}
\begin{defn}
    A function $f : X \to Y$ is 
    \begin{itemize}
        \item continuous at $x$ if $\forall \varepsilon > 0, \:
            \exists \delta > 0$ such that 
            \[
                d_Y(f(x), f(y)) < \varepsilon
            \]
            for every $y \in X$ satisfying $d_X(x,y) < \delta$.
        \item continuous if it is continuous at all 
            $x \in X$.
        \item uniformly continuous if 
            $\forall \varepsilon > 0, \: \exists \delta > 0$ s.t. 
            \[
                d_X(x,y) < \delta \Rightarrow d_Y(f(x),f(y))
            \]
            $\forall x,y \in X$.
        \item Lipschitz continuous if $\exists C > 0$ s.t. 
            \[
                d_Y(f(x),f(y)) < C d_x(x,y), \ \forall x,y \in X
            \]
    \end{itemize}
    with each subsequent property implying the one before it. 
\end{defn}
\begin{defn}
    Denote 
    \[
        C(X,Y) = \{\text{all continuous} \ f:X\to Y\}
    \]
    \[
        C(X) = C(X,\mathbb R)
    \]
\end{defn}
\begin{lem}
    If $f:A \to \mathbb R$ ($A \subseteq \mathbb R$) satisfies 
    $|f'(x)| \leq M, \: \forall x \in A$, then $f$ is 
    Lipschitz with constant $M$.
\end{lem}
\begin{lem}
    If $f : [a,b] \to \mathbb R$ is continuously differentiable, 
    then it is Lipschitz.
\end{lem}
\begin{thm}
    Let $f : X \to Y$ be continuous and $(X,d_X)$ compact. 
    Then $f$ is uniformly continuous.
\end{thm}

\newpage 
\section{Problems from week of 9/2 to 15/2}
\begin{prob}[Problem 5, Spaces p.67]
    Let $(X,d)$ be a metric space. For a subset $A \subseteq X$, 
    let $\partial A$ denote the set of all boundary points of $A$. 
    Recall that the closure of $A$ is $\overline A = A 
    \cup \partial A$. 

    \medskip

    a) A subset $A$ of $X$ is called \emph{precompact} if 
    $\overline A$ is compact. Show that $A$ is precompact if 
    and only if all sequences in $A$ have a convergent subsequence. 

    \medskip 

    b) Show that a subset of $\mathbb R^m$ is precompact if 
    and only if it is bounded. 
\end{prob}
\begin{proof}[Proof of (a)]
    Notice that what we're really saying here is that 
    $A$ is precompact if and only if $A$ is compact. 

    By an earlier theorem we have that if $A \subseteq X$ is 
    compact then it is closed and bounded. Namely 
    $A$ is closed so $A = \overline A$. Thus it is clear to 
    see that $A$ is precompact if and only if it is compact. 
\end{proof}
\begin{proof}[Proof of (b)]
    By an earlier proposition we have that a $A \subseteq \mathbb R^m$
    is compact if and only if it is closed and bounded. As we 
    saw in (a) we know that $A$ is precompact if and only 
    if it is compact. 
\end{proof}
\begin{prob}[Problem 6, Spaces p.67]
    Assume that $(X,d)$ is a metric space and that 
    $f : X \to [0,\infty)$ is continuous. Assume that for each 
    $\varepsilon > 0$, there is a compact set $K_\varepsilon 
    \subseteq X$ such taht $f(x) < \varepsilon$ when 
    $x \not\in K_\varepsilon$, Show that $f$ has a maximum point.
\end{prob}
\begin{proof}
    If $f \equiv 0$, then $f$ trivially attains its maximum.
    Assume therefore that there exists $x_0 \in X$ such that
    $f(x_0) > 0$.

    Let
    \[
        \varepsilon := \frac{1}{2} f(x_0) > 0.
    \]
    By assumption, there exists a compact set
    $K_\varepsilon \subseteq X$ such that
    \[
        f(x) < \varepsilon \quad \text{for all } x \notin K_\varepsilon.
    \]

    Since $f$ is continuous and $K_\varepsilon$ is compact, the
    restriction
    \[
        f\bigm|_{K_\varepsilon} : K_\varepsilon \to [0,\infty)
    \]
    attains a maximum. Let $x^* \in K_\varepsilon$ be such that
    \[
        f(x^*) = \max_{x \in K_\varepsilon} f(x) =: M.
    \]
    Note that
    \[
        M \ge f(x_0) > \varepsilon.
    \]

    Now let $x \in X$ be arbitrary. If $x \in K_\varepsilon$, then
    $f(x) \le M$. If $x \notin K_\varepsilon$, then
    \[
        f(x) < \varepsilon < M.
    \]
    Hence in all cases,
    \[
        f(x) \le M = f(x^*).
    \]

    Therefore $f$ attains its maximum at $x^*$.
\end{proof}

\begin{prob}[Problem 7 Spaces p.67]
    Let $(X,d)$ be a compact metric space, and assume that 
    $f : X \to \mathbb R$ is continuous when $\mathbb R$ is 
    given the usual metric. Show that if $f(x) > 0$ for 
    every $x \in X$, then there is a positive, real number
    $a$ such that $f(x) > a$ for every $x \in X$.
\end{prob}
\begin{proof}
    Notice that what the claim gives us is that 
    $f[X]$ is bounded below by some \emph{positive} real 
    number $a$. By assumption $f[X]$ is already bounded 
    below by $0$. We give a constructive argument 
    for the existence of $a > 0$ as follows: 

    As $f$ is continuous, $X$ compact, we conclude that 
    $f[X] \subseteq \mathbb R$ is compact. By the Heine-Borel 
    theorem $f[X]$ is closed and bounded. 
    Thus $\inf f[X]$ exists and furthermore $0 < \inf f[X] \in f[X]$.
    (We conclude that $\inf f[X]$ is strictly greater than $0$ 
    as $f(x) > 0$ by assumption).
    Let $a = \frac{1}{2} \inf f[X]$. 

    Clearly, 
    \[
        0 < a < \inf f[X]
    \]
    so 
    \[
        0 < a < f(x), \: \forall x \in X
    \]
    
\end{proof}

\begin{prob}[Problem 8 Spaces p.68]
    Assume that $f: X \to Y$ is a continuous function between 
    metric spaces, and let $K$ be a compact subset of $Y$. 
    Show that $f^{-1}(K)$ is closed. 
\end{prob}
\begin{proof}
    Let $K \subseteq Y$ compact, $f : X \to Y$ continuous, and denote 
    \[
        \Omega := f^{-1}[K] = \{x \in X \bigm| f(x) \in K\}
    \]
    Suppose $\Omega$ is open. Then there is some sequence 
    $\{x_n\}_{n\in\mathbb N}$ in $\Omega$ which converges 
    to a limit point $x \not\in \Omega$. 
    By sequential continuity we have that 
    \[
        f(x_n) \to f(x)
    \]
    $f(x_n) \in K$. Since $K$ is compact (and thus closed), 
    we conclude that 
    \[
        f(x) \in K
    \]
    so 
    \[
        x \in f^{-1}[K] = \Omega
    \]
    In other words, $x \in \Omega$ and $x \not\in \Omega$. 

    (No this did not need to be a proof by contradiction)
\end{proof}
\begin{prob}[Problem 9 Spaces p.68]
    Show that a totally bounded subset of a metric space is always
    bounded. Find an example of a bounded set in a metric space 
    that is not totally bounded. 
\end{prob}
\begin{proof}
    Let $(X,d)$ be a metric space with $K \subseteq X$ totally 
    bounded. Recall that what we mean by totally bounded is 
    that for every $\varepsilon > 0$, there exists finitely 
    many $x_1, \ldots, x_n \in K$ such that 
    \[
        K \subseteq \bigcup_{i=1}^n B(x_i;\varepsilon)
    \]
    $K$ is bounded if 
    \[
        K \subseteq B(x;r)
    \]
    for some $x \in K$ and $r > 0$.

    Pick $x := x_i$ for any $i \in [n]$, and let 
    \[
        r := \sup_{1 \leq j \leq n} d_X(x,x_j) 
        + \varepsilon
    \]
    Consider any $y \in B(x_j; \varepsilon)$.  
    Then 
    \[
        d_X(y,x_j) < \varepsilon
    \]
    and, by triangle inequality 
    \[
        d(y,x) \le d(y,x_j) + d(x_j,x)
    \]
    Hence, 
    \[
        d(y,x) < \varepsilon + d(x_j,x)
    \]
    Since $d(x_j,x) \le \sup_{1 \le j \le n} d(x,x_j)$, we get 
    \[
        d(y,x)< \varepsilon + \sup_{1 \le j \le n} d(x,x_j)
    \]
    As $r$ is defined, 
    \[
        \varepsilon + \sup_{j} d(x,x_j) = r
    \]
    Thus 
    \[
        d(y,x) < r.
    \]
    As $y \in B(x_j;\varepsilon)$ was arbitrarily chosen 
    we may conclude that 
    \[
        K \subseteq B(x;r)
    \]
\end{proof}

\begin{prob}[Problem 11 Spaces p.68]
    A metric space $(X,d)$ is locally compact if there for each 
    $a \in X$ is some $r > 0$ such that the closed ball 
    $\overline B(a;r)$ is compact. 

    a) Show that $\mathbb R^n$ is locally compact. 

    b) Show that if $X = \mathbb R \setminus \{0\}$, and 
    $d: X \to \mathbb R$ is the metric defined by $d(x,y) = |x-y|$, 
    then $(X,d)$ is locally compact, but not complete.  
\end{prob}
\begin{proof}[Proof of (a)]
    Let $a \in \mathbb R^n$ and take \emph{any} $r > 0$. 
    Clearly 
    \[
        \overline B(a;r)
    \]
    is closed and furthermore 
    \[
        \overline B(a;r) \subseteq \overline B(a;r)
    \]
    so bounded. 
    
    By the Heine-Borel theorem $\overline B(a;r)$ is compact. 
    As $a \in \mathbb R^n$ was chosen arbitrarily we conclude 
    that $\mathbb R^n$ is locally compact. 
\end{proof}
\begin{proof}[Proof of (b)]
    Pick any $a \in X$. If $a > 0$ we define the closed ball 
    \[
        a \pm \frac{|a|}{2} 
    \]
    which is clearly closed and bounded (thus compact). 

    The space is not complete because 
    \[
        \left\{\frac{1}{n}\right\}_{n\in\mathbb N} 
        \underset{n \to \infty}{\to} 0 \not\in X
    \]
    i.e. we have a cauchy sequence which does not converge 
    to a point in the space. 
\end{proof}
\begin{prob}[Problem 15 Spaces p.68]
    Assume that $C$ and $K$ are disjoint, compact subsets of a 
    metric space $(X,d)$, and define 
    \[
        a = \inf\left\{ d(x,y) \bigm| x \in C, y \in K \right\}
    \]
    Show that $a$ is strictly positive and that there 
    are point $x_0 \in C, \: y_0 \in K$ such that 
    $d(x_0, y_0) = a$. Show by an example that the result 
    does not hold if we only assume that one of the sets is compact 
    and the other is closed. 
\end{prob}
\begin{proof}
    As the metric is non-negative we can clearly see that 
    $a \geq 0$. Assume, in search of contradiction, that 
    $a = 0$.
    Then, for every $n \in \mathbb N$ there exists 
    $x_n \in C, \: y_n \in K$ such that 
    \[
        d(x_n, y_n) < \frac{1}{n}
    \]
    $C$ is compact so you can take a convergent subsequence 
    \[
        \{x_n(k)\}_k \to x_0 \in C
    \]
    Then, as  
    \[
        d(x_{n(k)}, y_{n(k)}) \to 0
    \]
    we see 
    \[
        \{y_{n(k)}\}_k \to x_0 \in K
    \]
    and thus conclude 
    \[
        x_0 \in C \cap K \neq \emptyset 
    \]
    contradiction our assumption. Hence $a > 0$. 

    Now consider two sequences $\{x_n\}_n \subseteq C$ 
    and $\{y_n\}_n \subseteq K$ such that 
    \[
        d(x_n, y_n) \underset{n \to \infty}{\to} a
    \]
    By sequential continuity (metric is continuous) we 
    get that 
    \[
        d(x_n, y_n) \to d(x,y)
    \]
    and by uniqueness of limit point we conclude that 
    \[
        d(x,y) = a
    \]
    Now, as $C$ and $K$ are compact we can find 
    convergent subsequences which must then again 
    converge to $x$ and $y$ in their respective sets. 
    In other words, 
    \[
        x \in C \ \text{and} \ y \in K
    \]
    Therefore you can find points in $C$ and $K$ such that 
    the minimum distance is attained. 

    (Perhaps this could have been shown by arguing that 
    as $d$ is continuous and thus the set of distances 
    between $C$ and $K$ are compact in $\mathbb R$ 
    ($\Rightarrow$ closed and bounded), the 
    extreme-value theorem applies?)
\end{proof}

\begin{prob}[Problem 2 Spaces p.80]
    Prove that $f:(0,1) \to \mathbb R$ given by $f(x) = \frac{1}{x}$
    is not uniformly continuous.
\end{prob}
\begin{proof}
    Recall that a function $f : X \to Y$ is uniformly continuous 
    if 
    \[
        \forall \varepsilon > 0, \: \exists \delta > 0 : 
        d_X(x,y) < \delta \Rightarrow d_Y(f(x),f(y)), 
        \: \forall x,y \in X
    \]
    Crucially there must be a $\delta$ for every $\varepsilon$ 
    which works at every point similtaneously.
    Informally, the problem with $\frac{1}{x}$ is that 
    it grows without bound when $x \to 0$. 
    
    Consider what happens as $x \to 0$. 
    Let $x_n = \frac{1}{n}$ and $y = \frac{1}{n+1}$. 
    Then 
    \[
        d_X(x_n, y_n) \underset{n\to\infty}{\to} 0
    \]
    but 
    \[
        d_Y(f(x_n),f(y_n)) = |n - (n + 1)| = 1
    \]
    So we can fix $\varepsilon_0 = 1/2$ and for 
    any $\delta > 0$ we can pick $n$ large enough so that 
    \[
        d_X(x_n,y_n) < \delta
    \]
    but 
    \[
        d_Y(f(x_n),f(y_n)) = 1 > \varepsilon_0
    \]
    
\end{proof}
\begin{prob}[Problem 4 Spaces p.80]
    Let $f : \mathbb R \to \mathbb R$ be a differentiable 
    function and assume that the derivative 
    $f'$ is bounded. Show that $f$ is uniformly continuous. 
\end{prob}
\begin{proof}
    We know that $f$ is a real-valued function such that there 
    exists $M \in \mathbb N$ for which
    \[
        \left|\frac{d}{dx}f(x)\right| = 
        \left|\lim_{h \to 0}\frac{f(x+h)-f(x)}{h}\right|
        \leq M, \: \forall x \in \mathbb R
    \]
    Suppose $f$ is not uniformly continuous. Then it is ceirtainly 
    not Lipschitz continuous. I.e. for every constant $C$ 
    there are points $x_C, y_C$ such that
    \[
        |f(x_C) - f(y_C)| > C|x_C-y_C| 
    \]
    Specifically: 
    \begin{align*}
        |f(x_M)-f(y_M)| &> M|x_M-y_M| 
        \\ 
        \left|\frac{f(x_M)-f(y_M)}{x_M-y_M}\right| &> M \\ 
        M \geq \left|\frac{f(x_M)-f(y_M)}{x_M-y_M}\right| &> M
    \end{align*}
    Our assumption that $f$ is not Lipschitz continuous 
    has led to a contradiction, so $f$ is Lipschitz and hence 
    uniformly continuous.
\end{proof}

\newpage  
\begin{prob}[A reach problem from section 4.6]
    Assume that $X \subset \mathbb R^n$ is not compact. 
    Show that there is an unbounded continuous function 
    $f: X \to \mathbb R$. 
\end{prob}
\begin{proof}   
    Recall that from the Heine-Borel theorem a 
    subset of $\mathbb R^n$ is compact if and only if 
    it is closed and bounded. Therefore 
    we may conclude that $X$ is either open or 
    unbounded. In the case where $X$ is unbounded 
    we construct the function $f : X \to \mathbb R$ with 
    \[
        f(x) = ||x||
    \]
    which very clearly is continuous and not bounded. 
    
    Now suppose $X$ is open. 
    Fix some $y \in \partial X \setminus X$. 
    Define $f : X \to \mathbb R$ as 
    \[
        f(x) = \frac{1}{||x-y||} = \frac{1}{d_X(x,y)} 
    \]
\end{proof}

\newpage 
\section{Spaces 4.2 - Models of convergence} 
\begin{defn}
    Let $(X,d_X), (Y,d_Y)$ be metric spaces. 

    Let $\{f_n\}_{n\in\mathbb N}$ be a sequence of functions 
    with domain $X$ and co-domain $Y$. Let $f : X \to Y$ be 
    another function. 

    We say that 
    $\{f_n\}_{n\in\mathbb N}$ converges to $f$ \emph{pointwise} 
    if $\forall \varepsilon > 0$ and $x \in X$ there exists 
    $n \in \mathbb N$ such that 
    \[
        d_Y(f_n(x),f(x)) < \varepsilon, \: \forall n \geq N
    \]
    and will often write $f_n \underset{n \to \infty}{\to} f$ 
    pointwise. 

    We say that $\{f_n\}_{n\in\mathbb N}$ converges to 
    $f$ \emph{uniformly} if $\forall \varepsilon > 0, \: \exists 
    N \in \mathbb N$ such that 
    \[
        d_Y(f_(x), f(x)) < \varepsilon, \: \forall n \geq N 
        \ \text{and} \ \forall x \in X
    \]
    and we often write $f_n \underset{n \to \infty}{\to} f$ 
    uniformly. 

    The difference being that for uniform convergence, 
    the choice of $N$ doens't depend on $x \in X$. 
\end{defn}
\begin{prop}
    Let $\{f_n\}_n$ be a sequence of $f_n : X \to Y$, and let 
    $f: X \to Y$. Then the following are equivalent. 

    \begin{enumerate}
        \item $f_n \to f$ pointwise.
        \item $f_n(x) \to f(x)$ for every $x \in X$. 
    \end{enumerate}
\end{prop}
\begin{defn}
    For $f,g : X \to Y$, define the supremum metric 
    \[
        \rho(f,g) = \sup_{x\in X} d_Y(f(x),g(x))
    \]
    also denoted 
    \[
        d_\infty(f,g), \ ||f-g||_\infty \ \text{or} \ 
        ||f-g||_{L^\infty}
    \]
\end{defn}
\begin{prop}
    Let $\{f_n\}_n$ be a sequence of functions from $X \to Y$, 
    and let $f: X \to Y$. Then the following are equivalent. 

    \begin{enumerate}
        \item $f_n \to f$ uniformly. 
        \item $\rho(f_n,f) \underset{n \to \infty}{\to} 0$.
    \end{enumerate}
\end{prop}

\begin{ex}
    Let $f_n, f : \mathbb R \to \mathbb R$, $f(x) = x^2$, 
    $f_n(x) = \min(n, x^2)$. Show that 
    $f_n$ converges to $f$ pointwise, but not uniformly. 
\end{ex}
\begin{proof}
    For any $x \in \mathbb R$, we have $f_n(x) = f(x)$ 
    for every $n \geq x^2$, so $f_n(x) \to f(x)$. 
    Next $\rho(f_n,f) = \sup_{x\in\mathbb R} |f_n(x) - f(x)| 
    = \sup_{x\in\mathbb R} |\min(n,x^2) - x^2| = \infty$.
\end{proof}
\begin{thm}
    Let $\{f_n\}_n$ be a sequence of $f_n : X \to Y$ and suppose 
    $f_n \to f$ uniformly for some $f : X \to Y$. 

    Then, $f$ is continuous.
\end{thm}

\newpage 
\section{Some problems for week of Feb 16th}
\begin{prob}
    Let $f_n : \mathbb R \to \mathbb R$ and assume that the 
    sequence $\{f_n\}_n$ of continuous functions converges 
    uniformly to $f : \mathbb R \to \mathbb R$ on 
    all intervals $[-k,k], \ k \in \mathbb N$. 
    Show that $f$ is continuous. 
\end{prob}
\begin{proof}
    Let $x_0 \in \mathbb{R}$ be arbitrary. We prove that $f$ is 
    continuous at $x_0$.

    Choose $k \in \mathbb{N}$ such that $k > |x_0| + 1$. 
    Then a neighbourhood of $x_0$ is contained in $[-k,k]$. 
    By assumption, $f_n \to f$ uniformly on $[-k,k]$.

    Let $\varepsilon > 0$ be given. 
    Since the convergence is uniform on $[-k,k]$, there exists 
    $N \in \mathbb{N}$ such that for all $x \in [-k,k]$ and all 
    $n \ge N$,
    \[
        |f_n(x) - f(x)| < \frac{\varepsilon}{3}.
    \]

    Fix such an $N$. 
    Because $f_N$ is continuous at $x_0$, there exists 
    $\delta > 0$ such that
    \[
        |x - x_0| < \delta 
        \quad \Rightarrow \quad 
        |f_N(x) - f_N(x_0)| < \frac{\varepsilon}{3}.
    \]

    We may assume $\delta \le 1$, so that 
    $|x - x_0| < \delta$ implies $x \in [-k,k]$.

    For such $x$ we estimate:
    \[
        \begin{aligned}
            |f(x) - f(x_0)|
&\le |f(x) - f_N(x)| 
+ |f_N(x) - f_N(x_0)| 
+ |f_N(x_0) - f(x_0)| \\
&< \frac{\varepsilon}{3} 
+ \frac{\varepsilon}{3} 
+ \frac{\varepsilon}{3} 
= \varepsilon.
        \end{aligned}
    \]

    Thus,
    \[
        |x - x_0| < \delta 
        \quad \Rightarrow \quad 
        |f(x) - f(x_0)| < \varepsilon.
    \]

    Since $\varepsilon > 0$ was arbitrary, $f$ is continuous at $x_0$. 
    Because $x_0$ was arbitrary, $f$ is continuous on $\mathbb{R}$.
\end{proof}
\begin{prob}[Problem 9, Spaces p.85]
    Let $(X,d)$ be a metric space and assume that the sequence 
    $f_n$ of continuous functions on $X$ converges uniformly 
    to $f$. Show that if $\{x_n\}_n$ is a sequence in $X$ converging 
    to $x$, then $f_n(x_n) \to f(x)$. Find an example which 
    shows that this is not necessarily the case if the 
    sequence of functions converges pointwise. 
\end{prob}
\begin{proof}
    Recall that, as $f_n \to f$ uniformly, we can for every 
    $\varepsilon$, find $N \in \mathbb N$ such that 
    \[
        d(f_n(x),f(x)) < \varepsilon, \: \forall n \geq N \ 
        \text{and} \ \forall x \in X
    \]
    As $f_n$ is continuous we can use the property of sequential 
    continuity. I.e. 
    \[
        f_n(x_{n'}) \underset{n' \to \infty}{\to} f_n(x) 
    \]
    Thus
    \[
        d(f_n(x_{n'}), f_n(x)) \to 0, \: n' \to \infty
    \]
    Let $\varepsilon > 0$.
    Pick $N \in \mathbb N$ such that 
    \[
        d(f_n(x_n), f_n(x)) < \varepsilon/2
    \]
    and 
    \[
        d(f_n(x), f(x)) < \varepsilon/2, \: \forall x \in X 
    \]
    Then 
    \[
        d(f_n(x_n), f(x)) \leq 
        d(f_n(x_n), f_n(x)) + d(f_n(x), f(x)) 
        < \varepsilon
    \]
\end{proof}

\begin{prob}[Problem 4.5.1, Spaces p.100]
    Let $f,g : [0,1] \to \mathbb R$ be given by 
    $f(x) = x, \: g(x) = x^2$. Find $\rho(f,g)$. 
\end{prob}
\begin{proof}[Solution]
    \[
        \rho(f,g) = \sup_{0\leq x \leq 1}|g(x) - f(x)|
    \]
    As $f,g$ continuous we know that there exists extremal values 
    in $[0,1]$. 
    $|f(0) - g(0)| = 0$ and $|f(1) - f(1)| = 0$ so 
    the endpoints are not it. We know that there must be some 
    point in $[0,1]$ where a maxima or minima of $g(x) - f(x)$ is 
    attained. 
    \begin{align*}
        g(x) - f(x) &= x^2 - x \\ 
                    &= x(x-1) \\ 
        \frac{d}{dx}(g-f)(x) &= 2x - 1\\  
        2x - 1 &= 0 \\ 
        x &= \frac{1}{2}
    \end{align*}
    $(g-f)(1/2) = - 1 / 4$ so 
    \[
        \rho(f,g) = \frac{1}{4}
    \]
\end{proof}
\begin{prob}[Problem 4.5.7, Spaces p.101]
    For $f \in B(\mathbb R, \mathbb R)$ and $r \in \mathbb R$, 
    we define a function $f_r$ by $f_r(x) = f(x + r)$. 

    a) Show that if $f$ is uniformly continuous, then 
    $\lim_{r\to 0}\rho(f_r,f) = 0$. 

    b) Show that the function $g$ defined by $g(x) = \cos(\pi x^2)$ 
    is not uniformly continuous on $\mathbb R$. 

    c) Is it true that $\lim_{r\to0}\rho(f_r,f) \to 0$ for 
    all $f \in B(\mathbb R, \mathbb R)$?
\end{prob}
\begin{proof}[Proof of (a)]
    Suppose $f \in B(\mathbb R, \mathbb R)$ is uniformly continuous. 
    Namely, $\forall \varepsilon > 0, \: \exists \delta > 0$ for 
    which 
    \[
        |x-y| < \delta \Rightarrow |f(x) - f(y)| < \varepsilon, 
        \: \forall x,y \in \mathbb R
    \]
    We are asked to show that 
    \[
        \lim_{r\to 0}\rho(f_r, f) = 0
    \]
    In other words  
    \[
        \sup_{x \in \mathbb R}|f(x+r)-f(x)| 
        \underset{r \to 0}{\to} 0
    \]
    Notice then that $f(x+r)$ converges to $f(x)$ for every $x$.
    Let $\varepsilon > 0$ and choose $\delta$ from uniform 
    continuity. If $|r| < \varepsilon$, then for every 
    $x\in \mathbb R$, 
    \[
        |(x+r) - r| = |r| < \delta
    \]
    Therefore 
    \[
        |f(x+r) - f(x)| < \varepsilon, \: \forall x\in\mathbb R
    \]
    Hence 
    \[
        \rho(f_r,f) \leq \varepsilon \ \text{whenever} \ |r| < \delta
    \]
    so 
    \[
        \lim_{r\to 0}\rho(f_r,f) = 0
    \]
\end{proof}

\begin{prob}
    The space $C_b(X,Y)$ is always "larger" than $Y$, in the sense that $Y$ can be embedded in $C_b(X,Y)$:

    Indeed, show that the map $i:Y\to C_b(X,Y)$ 
    which maps $y\in Y$ to the constant function $f(x)\equiv y$, is an embedding (cf. Definition 3.1.3).
    
    Show that $i(Y)$ is precisely the subset of constant functions, and that this set is a closed subset of $C_b(X,Y)$.
    
    Conclude that $C_b(X,Y)$ is complete if and only if $Y$ is complete.
\end{prob}
\begin{proof}[Proof sketch]
    Define $i: Y \to C_b(X,Y)$ by 
    \[
        y \mapsto f(x) \equiv y
    \]
    We begin by showing the necessary condition of an embedding 
    before arguing that it is injective (as the latter will 
    follow clearly from the former). 

    Let $y_1,y_2 \in Y$ and denote constant functions which map 
    to them by $f_{y_1}, f_{y_2}$ respectively. 
    \begin{align*}
        \rho(f_{y_1}, f_{y_2}) &= \sup_{x\in X}d_Y(f_{y_1}(x), 
        f_{y_2}(x)) \\ 
        &= \sup\{d_Y(y_1, y_2), d_Y(y_1,y_2) \ldots\} \\ 
        &= d_Y(y_1, y_2)
    \end{align*}
    It is clear that for distinct $y_1, y_2$ their images 
    are distinct since otherwise the supremum distance between 
    $f_{y_1}, f_{y_2}$ would be $0$, but then it would follow 
    that $d_Y(y_1, y_2) = 0$. Therefore we conclude that $i$ is 
    an injection.

    From a similar argument we can also see that there necessarily 
    exists one and only one constant function $f_y$ for every 
    $y \in Y$, so $i[Y]$ must be exactly the set of all of these, 
    and therefore we could create a one-to-one mapping 
    from $y$'s and constant functions.  
\end{proof}

\begin{prob}[Problem 4.6.1, Spaces p.102]
    Let $X,Y = \mathbb R$. Find functions $f,g \in C(X,Y)$ such 
    that 
    \[
        \sup_x\{d_Y(f(x),g(x))\} = \infty
    \]
\end{prob}
\begin{proof}[Solution]
    Consider $f,g : \mathbb R \to \mathbb R$ defined by 
    \[
        f(x) = x, \ g(x) = -x
    \]
    As $\mathbb R$ is finite-dimensional, every norm-induced metric 
    is equivalent so we work with $d_Y(x,y) = |x-y|$. 
    Thus 
    \[
        \rho(f,g) = \sup_x |f(x) - g(x)| 
        = 2 \sup_x|x|
    \]
    As $\mathbb R$ is unbounded $\sup_x|x| = \infty$. 
\end{proof}
\begin{prob}[Problem 4.6.2, Spaces p.102]
    Assume that $X \subseteq \mathbb R^n$ is not compact. 
    Show that there is an unbounded, continuous function 
    $f : X \to \mathbb R$. 
\end{prob}
\begin{proof}
    Recall that, from the Heine-Borel theorem, $X$ is either 
    unbounded or open. If $X$ is unbounded we can trivially find 
    the unbounded continuous function
    \[
        f : X \to \mathbb R, f(x) = x
    \]
    Constant functions are (Lipschitz) continuous and 
    this function $f$ is unbounded as $X$ is unbounded. 
    (For every $M > 0$ there exists $x \in X$ such that 
    $||x|| > M$). 

    If $X$ is open we can define $f : X \to \mathbb R$ as follows. 
    Fix some $y \in \partial X$ ($y \not\in X$ by definition) and 
    let 
    \[
        f(x) = \frac{1}{||x - y||}
    \]
    can take on arbitrarily large values. (Consider some 
    sequence in $X$ converging to $y$ will always be well-defined  
    for $x_n$, but grow undbounded).  
\end{proof}
\begin{prob}[Problem 4.6.3, Spaces p.102]
    Assume that $f : \mathbb R \to \mathbb R$ is a bounded 
    continuous function. If $u \in C([0,1],\mathbb R)$, we 
    define $L(u):[0,1]\to \mathbb R$ to be the function 
    \[
        L(u)(t) \int_{0}^1 \frac{1}{1+t+s}f(u(s)) ds.
    \]

    a) Show that $L$ is a function from $C([0,1],\mathbb R)$ to 
    $C([0,1],\mathbb R)$. 

    b) Show that ... 
\end{prob}
\begin{proof}[Proof of (a)]
    proof
\end{proof}

\newpage 
\section{Integrating sequences of functions}
\begin{thm}
    Let $f_n : [a,b] \to \mathbb R$ be continuous 
    $\forall n \in \mathbb N$ and assume 
    $f_n \to f$ uniformly. Let $F_n(x) = 
    \displaystyle\int_a^x f_n(t) \;dt, \ F(x) = 
    \displaystyle\int_a^x f(t) \; dt$. 

    Then $F_n \to F$ uniformly. 
\end{thm}
\begin{proof}
    Let $\varepsilon > 0$ and let $N \in \mathbb N$ be such that 
    \[
        \rho(f_n,f) < \varepsilon
    \]
    when $n \geq N$. Then 
    \begin{align*}
        |F_n(x) - F(x)| &= \left|\displaystyle\int_a^x f_n(t) 
        - f(t) \; dt\right| \\ 
                        &\leq \displaystyle\int_a^x \left|
                        f_n(t) - f(t) \right| \; dt \\ 
                        &\leq \displaystyle\int_a^x \rho(f_n,f) \; dt 
                        \\ 
                        &= (x-a)\rho(f_n,f) < (b-a) \varepsilon
    \end{align*}
\end{proof}

Next we look at the following. Given $v_1,v_2,\ldots : [a,b] 
\to \mathbb R$, what do we mean by 
\[
    \displaystyle\sum_{n=1}^{\infty}v_n(x)\; ?
\]

Recall that if $a_1,a_2,\ldots$ are numbers we say that 
\[
    \displaystyle\sum_{n=1}^{\infty}a_n \ \textbf{converges}
\]
if the partial sums $S_n = \sum_{n=1}^{N}a_n$ converge as 
$N \to \infty$. 

\begin{defn}
    Let $(X,d)$ be a metric space. Let $A \subseteq X$ and let 
    $\{v_n\}_{n \in \mathbb N}$ be a sequence of functions 
    $v_n : A \to \mathbb R$. We say that the series 
    $\sum_{n=1}^\infty v_n$ 
    \begin{itemize}
        \item \textbf{converges pointwise} if for every 
            $x \in A$, the partial sums 
            $S_N(x) = \sum_{n=1}^{N}v_n(x)$ converge as $N 
            \to \infty$
        \item \textbf{converges uniformly} if the partial sums $S_N$ 
            converge uniformly as $N \to \infty$. 
    \end{itemize}
\end{defn}
\begin{lem}[Weierstrass M-test]
    Assume that there are numbers $M_n \geq 0$ such that 
    \begin{itemize}
        \item $|v_n(x)| \leq M_n, \: \forall x \in A$
        \item $\sum_{n=1}^\infty M_n < \infty$
    \end{itemize}
    Then $\sum_{n=1}^{\infty}v_n$ converges uniformly.
\end{lem}
\begin{thm}
    Let $v_n : [a,b] \to \mathbb R$ be continuous $\forall n \in 
    \mathbb N$ and assume $\sum_{n=1}^{\infty}v_n$ converges 
    uniformly. Let $V_n(x) := \displaystyle\int_{a}^{x}v_n(t) \; dt$. 

    Then the series $\sum_{n=1}^{\infty}V_n$ converges uniformly, 
    and 
    \[
        \displaystyle\sum_{n=1}^\infty V_n(x) = 
        \displaystyle\int_{a}^{x}\displaystyle\sum_{n=1}^\infty 
        v_n(t) \; dt, \ \forall x \in [a,b]
    \]
\end{thm}
\begin{thm}
    Let $f_n : [a,b] \to \mathbb R$ be continuously differentiable 
    $\forall n \in \mathbb N$. Assume 
    \begin{itemize}
        \item $\{f'_n\}_{n\in\mathbb N}$ 
                converges uniformly to some $g : [a,b] 
            \to \mathbb R$ 
        \item $\{f_n(x_0)\}_{n\in\mathbb N}$ converges to some 
            $\alpha \in \mathbb R$, for some $x_0 \in \mathbb R$
    \end{itemize}
    Then $f_n \to f $ uniformly for some $f : [a,b] \to \mathbb R$
    with $f' = g$ and $f(x_0 ) = \alpha$.
\end{thm}
\begin{thm}
    If $\{u_n\}_n$ is a sequence of continuously differentiable 
    functions $u_n : [a,b] \to \mathbb R$ such that 
    $\sum_{n=1}^{\infty}u_n'$ converges uniformly and 
    $\sum_{n=1}^{\infty}u_n(x_0)$ converges for some $x_0 \in [a,b]$,
    then $\sum_{n=1}^{\infty}u_n$ converges uniformly, and 
    \[
        \frac{d}{dx} \left( \displaystyle\sum_{n=1}^{\infty}u_n  
        \right) = \displaystyle\sum_{n=1}^{\infty}\left( 
        \frac{d}{dx} u_n\right)
    \]
\end{thm}

\newpage 
\section{Tasks from week of 23 Feb}
\begin{prob}[Problem 1, Spaces p.91]
    Show that $\sum_{n=1}^{\infty}\frac{\cos(nx)}{n^2 + 1}$ converges
    uniformly on $\mathbb R$.
\end{prob}
\begin{proof}
    We prove the claim by applying the Weierstrass M-test. 

    It is clear that $\cos(nx)/(n^2+1)$ is bounded by 
    $\frac{1}{n^2 + 1}$ as $|\cos(nx)| \leq 1$. 
    Furthermore 
    \[
        \displaystyle\sum_{n=1}^{\infty}\frac{1}{n^2 + 1} \leq
        \displaystyle\sum_{n=1}^{\infty}\frac{1}{n^2} = 
        \frac{\pi^2}{6} < \infty
    \]
    By the Weierstrass M-test,  
    \[
        \displaystyle\sum_{n=1}^{\infty}\frac{\cos(nx)}{n^2 + 1}
    \]
    \textbf{converges uniformly} on $\mathbb R$.
\end{proof}

\end{document}
